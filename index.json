[{"content":"基本语法 targets: prerequisites command command command 变量 声明变量\nNAME=ClashV BINDIR=bin 使用$()来引用变量\nPLATFORM_LIST = \\ darwin-amd64 \\ darwin-amd64-compatible \\ all-arch: $(PLATFORM_LIST) 自动变量 $@: 表示target\ndarwin-amd64: GOARCH=amd64 GOOS=darwin $(GOBUILD) -o $(BINDIR)/$(NAME)-$@ 条件判断 ifeq ($(BRANCH),Alpha) VERSION=alpha-$(shell git rev-parse --short HEAD) else ifeq ($(BRANCH),Beta) VERSION=beta-$(shell git rev-parse --short HEAD) else ifeq ($(BRANCH),) VERSION=$(shell git describe --tags) else VERSION=$(shell git rev-parse --short HEAD) endif 函数 shell BRANCH=$(shell git branch --show-current) 相关链接 Makefile Tutorial ","permalink":"https://carlos19960601.github.io/posts/%E6%80%8E%E4%B9%88%E5%86%99makefile/","summary":"基本语法 targets: prerequisites command command command 变量 声明变量\nNAME=ClashV BINDIR=bin 使用$()来引用变量\nPLATFORM_LIST = \\ darwin-amd64 \\ darwin-amd64-compatible \\ all-arch: $(PLATFORM_LIST) 自动变量 $@: 表示target\ndarwin-amd64: GOARCH=amd64 GOOS=darwin $(GOBUILD) -o $(BINDIR)/$(NAME)-$@ 条件判断 ifeq ($(BRANCH),Alpha) VERSION=alpha-$(shell git rev-parse --short HEAD) else ifeq ($(BRANCH),Beta) VERSION=beta-$(shell git rev-parse --short HEAD) else ifeq ($(BRANCH),) VERSION=$(shell git describe --tags) else VERSION=$(shell git rev-parse --short HEAD) endif 函数 shell BRANCH=$(shell git branch --show-current) 相关链接 Makefile Tutorial ","title":"怎么写Makefile"},{"content":" react-rough-fiber: 渲染手绘风 SVG 的 React 渲染器，可以轻松把 SVG 转换成手绘风图片 ","permalink":"https://carlos19960601.github.io/posts/%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE%E6%8E%A8%E8%8D%90/","summary":" react-rough-fiber: 渲染手绘风 SVG 的 React 渲染器，可以轻松把 SVG 转换成手绘风图片 ","title":"开源项目推荐【持续更新】"},{"content":" happyhues: 网站颜色搭配神器 ","permalink":"https://carlos19960601.github.io/posts/%E5%B7%A5%E5%85%B7%E6%8E%A8%E8%8D%90/","summary":" happyhues: 网站颜色搭配神器 ","title":"工具推荐【持续更新】"},{"content":" Least Recently Used(LRU): 删除最旧的数据。基本假设是最近访问的数据可能很快会再次被需要。 Most Recently Used(MRU): 与LRU相反，删除最新的数据。常用于流处理或批处理平台，这些平台一旦使用数据就不太可能再次需要。 Least Frequently Used(LFU): 删除使用最少的数据。虽然它是一种比 LRU 更准确的方法，但它需要一种机制来记录数据访问的频率，这增加了复杂性。它通常与 LRU 等策略配合使用，以降低缓存过时数据的风险。 Time-To-Live (TTL)：数据在预设的时间段有效。常用在会话数据中。 Two-tiered caching两层缓存提供了一种更复杂的方法。可以在速度和成本之间取得平衡。在此设计中，数据被分为快速、昂贵的层（用于流行数据）和较慢、经济的层（用于较少访问的数据）。 上述五种策略是最流行的缓存方法。还有其他一些策略：\n先进先出（FIFO）：最旧的数据首先被删除。 随机替换（RR）：随机选择要删除的数据。 自适应替换缓存 (ARC)：使用自调整算法跟踪新近度和频率来确定首先删除哪些数据。 ","permalink":"https://carlos19960601.github.io/posts/%E7%BC%93%E5%AD%98%E9%A9%B1%E9%80%90%E7%AD%96%E7%95%A5/","summary":" Least Recently Used(LRU): 删除最旧的数据。基本假设是最近访问的数据可能很快会再次被需要。 Most Recently Used(MRU): 与LRU相反，删除最新的数据。常用于流处理或批处理平台，这些平台一旦使用数据就不太可能再次需要。 Least Frequently Used(LFU): 删除使用最少的数据。虽然它是一种比 LRU 更准确的方法，但它需要一种机制来记录数据访问的频率，这增加了复杂性。它通常与 LRU 等策略配合使用，以降低缓存过时数据的风险。 Time-To-Live (TTL)：数据在预设的时间段有效。常用在会话数据中。 Two-tiered caching两层缓存提供了一种更复杂的方法。可以在速度和成本之间取得平衡。在此设计中，数据被分为快速、昂贵的层（用于流行数据）和较慢、经济的层（用于较少访问的数据）。 上述五种策略是最流行的缓存方法。还有其他一些策略：\n先进先出（FIFO）：最旧的数据首先被删除。 随机替换（RR）：随机选择要删除的数据。 自适应替换缓存 (ARC)：使用自调整算法跟踪新近度和频率来确定首先删除哪些数据。 ","title":"缓存驱逐策略"},{"content":"先看这段代码\nimport ( \u0026#34;io\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;sync/atomic\u0026#34; ) func main() { var v atomic.Value var err error err = \u0026amp;http.ProtocolError{} v.Store(err) err = io.EOF v.Store(err) } 运行后会报错 panic: sync/atomic: store of inconsistently typed value into Value。\n原因是atomic.Value.Store需要类型是一致的。在这里err类型发生了变化，虽然他们都是error接口类型。具体参考Issues#22550\n怎么解决？包装一层就能运行了。\ntype tValue[T any] struct { value T } func main() { var v atomic.Value var err error err = \u0026amp;http.ProtocolError{} v.Store(tValue[error]{err}) err = io.EOF v.Store(tValue[error]{err}) } ","permalink":"https://carlos19960601.github.io/posts/atomic.value%E5%AD%98%E5%82%A8interface%E7%9A%84%E9%97%AE%E9%A2%98/","summary":"先看这段代码\nimport ( \u0026#34;io\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;sync/atomic\u0026#34; ) func main() { var v atomic.Value var err error err = \u0026amp;http.ProtocolError{} v.Store(err) err = io.EOF v.Store(err) } 运行后会报错 panic: sync/atomic: store of inconsistently typed value into Value。\n原因是atomic.Value.Store需要类型是一致的。在这里err类型发生了变化，虽然他们都是error接口类型。具体参考Issues#22550\n怎么解决？包装一层就能运行了。\ntype tValue[T any] struct { value T } func main() { var v atomic.Value var err error err = \u0026amp;http.ProtocolError{} v.Store(tValue[error]{err}) err = io.EOF v.Store(tValue[error]{err}) } ","title":"atomic.Value存储interface的问题"},{"content":"很早之前做的一次分享，下面是PPT内容\n","permalink":"https://carlos19960601.github.io/posts/mysql%E5%AD%98%E5%82%A8%E4%B8%8E%E7%B4%A2%E5%BC%95%E5%8E%9F%E7%90%86%E5%88%86%E4%BA%AB/","summary":"很早之前做的一次分享，下面是PPT内容","title":"MySQL存储与索引原理分享"},{"content":"由于GC复杂，我也没有仔细研究过GC的源码，所以只能站在巨人的肩上学习，如果想了解GC的具体实现请移步文末的参考资料。本文只是记录我在阅读完大佬文章中自己的一些问题与思考，可能有一些不对的地方。欢迎大家一起讨论。\n清理阶段，新产生的对象被标记成白色，岂不是会被回收掉？ 在参考文章1留言中也有人提了这个问题\n我再将问题描述一下\n在标记完成的时候会STW，将状态切换成_GCoff，然后就会进入清理阶段，进入清理阶段的时候，已经结束标记阶段，所以这个时候就没有颜色的区分了(当然也可以说新产生的对象时白色的，因为GC开始的时候默认所有的对象都是白色)。\n那新产生的对象，在清理阶段会被回收吗？肯定是不会的，要不然早就崩了，为什么没有被回收呢\n我个人理解是这样的，清理阶段，当Goroutine申请新内存的时候就会触发清理，先进行清理再进行对象的分配，这样就没问题了。因为已经清理了，所以后续也不会清理这块内存了，新对象在清理后再分配也就不会有问题了。\n栈上的黑色对象指向了堆中的白色对象？ 在参考文章1留言中也有人提了这个问题，我就不再重新描述了\n我还是说下我的理解，首先栈分为3种\n还没没有扫描的栈 扫描中的栈 扫描过的栈 如果是扫描中的栈，Groutine是暂停的，也就是栈上的对象不会发生变化，就不再讨论\n如果是还没有扫描的栈，因为栈在最开始的时候都被标记成灰色，不管栈上的对象引用怎么变化，最后都会扫描栈，所以也不会有啥问题\n如果是扫描过的栈，如果发生栈上的对象引用的变化，由于已经扫描过了，不会再扫描，所以就会有问题。但事实上却没有问题，为什么？\n在参考资料golang 混合写屏障原理深入剖析，这篇文章给你梳理的明明白白！！！中说明这个问题的原因\n问题在图片中描述得比较清楚了，栈上的A想要指向堆中的C，有多种方式\nA.C = new(C) A.C = B.C A.C = A.X.C 第1种方式，直接在堆中初始化C，然后A.C指向过去；如果是这样，C就不会是白色的，因为现在正在标记阶段，新对象都是黑色的\n第2种方式，这种是不可能的，Goroutine1栈中能访问到Goroutine2栈中的对象根本就不可能\n第3种方法是A能访问到X，X引用了C，如果是这样，因为Goroutine1已经被扫描过了，A还能访问到X，说明X一定不是白色的，X引用了C，当扫描X的时候C一定不会被标记成白色\n综上所述，Goroutine1栈中的A想要指向堆中的白色对象是不可能。\n删除写屏障到底是把什么对象染成灰色 理解混合写屏障一定要先理解删除写屏障 很多人都能理解插入写屏障，插入写屏障的流程个人理解如下：\nSTW，扫描栈上的对象，标记成灰色 恢复运行，开始并发标记 STW，重新扫描栈，完成标记阶段 由于栈上的对象被当作根对象，栈上的对象发生变更的时候，需要触发插入写屏障，由于栈上的操作频繁，而且要实现栈上的插入写屏障很复杂。所以Golang并没有实现栈上的插入写屏障\n但此时可能会出现如下的情况，栈上的黑色对象会指向白色对象。于是需要在标记完成的时候对栈进行了重新扫描，这时需要STW，这个过程大概需要花费10ms~100ms\n删除写屏障\n删除写屏障也叫基于快照的写屏障方案，必须在起始时，STW 扫描整个栈（注意了，是所有的 goroutine 栈），保证所有堆上在用的对象都处于灰色保护下，保证的是弱三色不变式； 由于起始快照的原因，起始也是执行 STW，删除写屏障不适用于栈特别大的场景，栈越大，STW 扫描时间越长，对于现代服务器上的程序来说，栈地址空间都很大，所以删除写屏障都不适用，一般适用于很小的栈内存，比如嵌入式，物联网的一些程序； 并且删除写屏障会导致扫描进度（波面）的后退，所以扫描精度不如插入写屏障； 思考问题：我不整机暂停 STW 栈，而是一个栈一个栈的快照，这样也没有 STW 了，是否可以满足要求？（这个就是当前 golang 混合写屏障的时候做的哈，虽然没有 STW 了，但是扫描到某一个具体的栈的时候，还是要暂停这一个 goroutine 的）\n不行，纯粹的删除写屏障，起始必须整个栈打快照，要把所有的堆对象都处于灰色保护中才行。\n举例：如果没有把栈完全扫黑，那么可能出现丢数据，如下：\n初始状态：\nA 是 g1 栈的一个对象，g1栈已经扫描完了，并且 C 也是扫黑了的对象； B 是 g2 栈的对象，指向了 C 和 D，g2 完全还没扫描，B 是一个灰色对象，D 是白色对象； 步骤一：g2 进行赋值变更，把 C 指向 D 对象，这个时候黑色的 C 就指向了白色的 D（由于是删除屏障，这里是不会触发hook的）\n步骤二：把 B 指向 C 的引用删除，由于是栈对象操作，不会触发删除写屏障；\n步骤三：清理，因为 C 已经是黑色对象了，所以不会再扫描，所以 D 就会被错误的清理掉。\n解决办法有如下：\n方法一：栈上对象也 hook，所有对象赋值（插入，删除）都 hook（这个就不实际了）;\n所有的插入，删除如果都 hook ，那么一定都不会有问题，虽然本轮精度很差，但是下轮回收可以回收了。但是还是那句话，栈，寄存器的赋值 hook 是不现实的。\n方法二：起始快照整栈扫黑，使得整个堆上的在用对象都处于灰色保护；\n整栈扫黑，那么在用的堆上的对象是一定处于灰色堆对象的保护下的，之后配合堆对象删除写屏障就能保证在用对象不丢失。\n方法三：加入插入写屏障的逻辑，C 指向 D 的时候，把 D 置灰，这样扫描也没问题。这样就能去掉起始 STW 扫描，从而可以并发，一个一个栈扫描。\n细品下，这不就成了当前在用的混合写屏障了，所以我觉得正确的理解方式应该是：混合写屏障 = 删除写屏障 + 插入写屏障，必须先理解下删除写屏障，你才能理解混合写屏障。\n混合写屏障current stack is grey的 理解 在混合写屏障中许多文章都这么描述\nwritePointer(slot, ptr): shade(*slot) if current stack is grey: shade(ptr) *slot = ptr current stack is grey该怎么理解\nProposal中是这么描述的\nif the current goroutine\u0026rsquo;s stack has not yet been scanned, also shades the reference being installed.\n翻译过来就是当前栈还没有被被扫描的时候，需要使用插入写屏障\n首先看一下栈已经被扫描的情况\n正在被扫描/未被扫描的栈\n栈被扫描过的存在上面2种情况\n栈上以及相关联堆上的对象都已经被标记成黑色 栈上的是黑色，堆上部分对象还没有被标记成黑色 这2种情况下即使不使用插入写屏障也不会出现黑色对象指向白色对象的情况\n要想让黑色对象指向白色对象有2种途径\n当前栈中的白色对象（这种情况下就是上图所示，E对象在灰色D对象的保护下，最后还是会被扫描成黑色，所以不会有问题） 其他栈引用了当前栈的黑色对象，将该黑色对象指向了白色对象(这个属于栈未被扫描，会正在扫描的情况，后面说这种情况) 接下来是栈正在被扫描或者未被扫描的情况，如下图\n如果不开启插入写屏障就会出现黑色对象指向白色对象的情况，所以这种情况下需要开启插入写屏障\n参考资料 Go 语言垃圾收集器的实现原理\nGo语言GC实现原理及源码分析 - luozhiyun`s Blog\nProposal: Eliminate STW stack re-scanning\ngolang 垃圾回收 （一）概述篇\ngolang 垃圾回收（二）屏障技术\ngolang 垃圾回收（三）插入写屏障\ngolang 垃圾回收 - 删除写屏障\ngolang 混合写屏障原理深入剖析，这篇文章给你梳理的明明白白！！！\nGolang垃圾回收 屏障技术\n","permalink":"https://carlos19960601.github.io/posts/%E5%85%B3%E4%BA%8Egolang-gc%E9%97%AE%E9%A2%98%E7%9A%84%E6%80%9D%E8%80%83/","summary":"\u003cp\u003e由于GC复杂，我也没有仔细研究过GC的源码，所以只能站在巨人的肩上学习，如果想了解GC的具体实现请移步文末的参考资料。本文只是记录我在阅读完大佬文章中自己的一些问题与思考，可能有一些不对的地方。欢迎大家一起讨论。\u003c/p\u003e","title":"关于Golang GC问题的思考"},{"content":"这是在小团队里面的一次分享，以下是PPT内容\n","permalink":"https://carlos19960601.github.io/posts/timer%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E5%88%86%E4%BA%AB/","summary":"这是在小团队里面的一次分享，以下是PPT内容","title":"Timer源码阅读分享"},{"content":"根据6.3 计时器中的描述，Golang Timer的设计经历了如下阶段：\nGo 1.9 版本之前，所有的计时器由全局唯一的四叉堆维护； Go 1.10 ~ 1.13，全局使用 64 个四叉堆维护全部的计时器，每个处理器（P）创建的计时器会由对应的四叉堆维护； Go 1.14 版本之后，每个处理器单独管理计时器并通过网络轮询器触发； Go 1.9 版本之前由于使用全局的四叉堆，在多核情况下会出现锁竞争导致性能问题 Go 1.10 ~ 1.13使用了64个四叉堆，有每个P来维护对应的四叉堆，相当于将锁的粒度减小，但是当timer在未到时间和到时间需要执行进行切换的时候，会发生P和M的绑定和解绑，尤其是当timer触发时间间隔比较小的情况下，会导致CPU占用过高，M/P切换的开销增加(TODO 为什么会发生P和M的绑定和解绑) Go 1.14 版本后每个P管理计时器四叉堆，由网络轮询器和调度器进行触发 我使用的是Go 1.16的版本进行分析\ntimer包的使用 主要分为2类，一次性触发的timer和多次触发的ticker\nfunc TestTimer(t *testing.T) { timer := time.NewTimer(time.Second) // for tm := range timer.C { // t.Log(tm) // timer.Reset(time.Second) // } var ch chan int for { select { case tm := \u0026lt;-timer.C: t.Log(tm) timer.Reset(time.Second) case \u0026lt;-ch: } } } func TestAfter(t *testing.T) { var ch chan int select { case tm := \u0026lt;-time.After(time.Second): t.Log(tm) case \u0026lt;-ch: } } func TestAfterFunc(t *testing.T) { var ch chan int timer := time.AfterFunc(time.Second, func() { t.Log(\u0026#34;我执行了\u0026#34;) ch \u0026lt;- 0 }) defer timer.Stop() \u0026lt;-ch } func TestTicker(t *testing.T) { ticker := time.NewTicker(time.Second) var ch chan int for { select { case tm := \u0026lt;-ticker.C: t.Log(tm) case \u0026lt;-ch: } } } func NewTicker(d Duration) *Ticker { if d \u0026lt;= 0 { panic(errors.New(\u0026#34;non-positive interval for NewTicker\u0026#34;)) } // Give the channel a 1-element time buffer. // If the client falls behind while reading, we drop ticks // on the floor until the client catches up. c := make(chan Time, 1) t := \u0026amp;Ticker{ C: c, r: runtimeTimer{ when: when(d), period: int64(d), f: sendTime, arg: c, }, } startTimer(\u0026amp;t.r) return t } func TestTick(t *testing.T) { for tm := range time.Tick(time.Second) { t.Log(tm) } } 需要注意的是，在for循环中使用的时候需要考虑是否会造成timer的泄漏；具体的示例分析可以参考 Go 内存泄露之痛，这篇把 Go timer.After 问题根因讲透了！\n数据结构 func NewTimer(d Duration) *Timer { c := make(chan Time, 1) t := \u0026amp;Timer{ C: c, r: runtimeTimer{ when: when(d), f: sendTime, arg: c, }, } startTimer(\u0026amp;t.r) return t } 可以看到NewTimer和NewTicker都会初始化runtimeTimer，差别在于Ticker会比Timer多了period参数。最后调用startTimer将timer添加到底层的最小四叉堆中\nruntimeTimer和runtime/time.go#timer结构是保持一致的\ntype timer struct { // If this timer is on a heap, which P\u0026#39;s heap it is on. // puintptr rather than *p to match uintptr in the versions // of this struct defined in other packages. pp puintptr // 当前P的指针 // Timer wakes up at when, and then at when+period, ... (period \u0026gt; 0 only) // each time calling f(arg, now) in the timer goroutine, so f must be // a well-behaved function and not block. // // when must be positive on an active timer. when int64 // 当前计时器被唤醒的时间 period int64 // 两次被唤醒的间隔 f func(interface{}, uintptr) // 每当计时器被唤醒时都会调用的函数 arg interface{} // 计时器被唤醒时调用 f 传入的参数 seq uintptr // What to set the when field to in timerModifiedXX status. nextwhen int64 // 计时器处于 timerModifiedXX 状态时，用于设置 when 字段； // The status field holds one of the values below. status uint32 // 计时器的状态 } 添加timer 前面的startTimer方法其实是runtime/time.go中的startTimer方法，通过//go:linkname关联起来的\n// 把 t 添加到 timer 堆 // startTimer adds t to the timer heap. //go:linkname startTimer time.startTimer func startTimer(t *timer) { if raceenabled { racerelease(unsafe.Pointer(t)) } addtimer(t) } 继续调用addtimer方法\n// addtimer adds a timer to the current P. // This should only be called with a newly created timer. // That avoids the risk of changing the when field of a timer in some P\u0026#39;s heap, // which could cause the heap to become unsorted. func addtimer(t *timer) { // when must be positive. A negative value will cause runtimer to // overflow during its delta calculation and never expire other runtime // timers. Zero will cause checkTimers to fail to notice the timer. if t.when \u0026lt;= 0 { throw(\u0026#34;timer when must be positive\u0026#34;) } if t.period \u0026lt; 0 { throw(\u0026#34;timer period must be non-negative\u0026#34;) } if t.status != timerNoStatus { // 添加新的timer必须是timerNoStatus throw(\u0026#34;addtimer called with initialized timer\u0026#34;) } t.status = timerWaiting when := t.when pp := getg().m.p.ptr() lock(\u0026amp;pp.timersLock) cleantimers(pp) doaddtimer(pp, t) unlock(\u0026amp;pp.timersLock) wakeNetPoller(when) } addtimer首先对参数进行了校验，timer的初始化status必须是timerNoStatus(计时器尚未设置状态)，然后将timer的status切换成timerWaiting(等待计时器启动)\n然后调用cleantimers(pp)处理P中timers堆顶上已经取消(timerDeleted)或者时间发生改变(timerModifiedEarlier/timerModifiedLater的timer)，对timers进行清理\n// 清理堆顶部的timer，与adjusttimers方法类似，只是adjusttimers会遍历搜索的timers // 注意cleantimers清理的是堆顶部的timer，只要顶部是timerDeleted，timerModifiedEarlier/timerModifiedLater的timer都会处理 // 处理完后会调整堆，再处理堆顶部的timer，所以不只是处理1个timer， // 当堆前面的timer是timerDeleted，timerModifiedEarlier/timerModifiedLater状态的时候都会进行处理 // adjusttimers不管是什么状态的timer，都会便利处理一遍 // cleantimers会出现下面2种状态的变化，也就是清除已经删除的，移动timer0 // timerDeleted -\u0026gt; timerRemoving -\u0026gt; timerRemoved // timerModifiedEarlier/timerModifiedLater -\u0026gt; timerMoving -\u0026gt; timerWaiting func cleantimers(pp *p) { gp := getg() for { if len(pp.timers) == 0 { return } // This loop can theoretically run for a while, and because // it is holding timersLock it cannot be preempted. // If someone is trying to preempt us, just return. // We can clean the timers later. if gp.preemptStop { return } t := pp.timers[0] // 堆顶，when最小，最早发生的timer if t.pp.ptr() != pp { throw(\u0026#34;cleantimers: bad p\u0026#34;) } switch s := atomic.Load(\u0026amp;t.status); s { case timerDeleted: // timerDeleted --\u0026gt; timerRemoving --\u0026gt; 从堆中删除timer --\u0026gt; timerRemoved if !atomic.Cas(\u0026amp;t.status, s, timerRemoving) { continue } dodeltimer0(pp) if !atomic.Cas(\u0026amp;t.status, timerRemoving, timerRemoved) { badTimer() } atomic.Xadd(\u0026amp;pp.deletedTimers, -1) case timerModifiedEarlier, timerModifiedLater: // TODO 如果modTimer将非timer0的when改成了比timer0更先触发的时候是怎么处理的 // timerMoving --\u0026gt; 调整 timer 的时间 --\u0026gt; timerWaiting // 此时 timer 被调整为更早或更晚，将原先的 timer 进行删除，再重新添加 if !atomic.Cas(\u0026amp;t.status, s, timerMoving) { continue } // Now we can change the when field. t.when = t.nextwhen // Move t to the right position. // 删除原来的 dodeltimer0(pp) // 然后再重新添加 doaddtimer(pp, t) if s == timerModifiedEarlier { atomic.Xadd(\u0026amp;pp.adjustTimers, -1) // 如果t0之前是timerModifiedEarlier，因为已经调整了t0，所以需要将adjustTimers减1 } if !atomic.Cas(\u0026amp;t.status, timerMoving, timerWaiting) { badTimer() } default: // Head of timers does not need adjustment. return } } } cleantimers(pp *p)方法会循环处理堆顶部是timerDeleted，timerModifiedEarlier/timerModifiedLater的timer\n如果是timerDeleted，说明timer已经取消了，从timers堆中删除，重新调整timers堆 如果是timerModifiedEarlier/timerModifiedLater，说明timer的时间发生改变，修改timer的when字段，删除之前的timer，重新添加新的timer cleantimers(pp *p)方法只是对p中的timers堆做了一些清理调整的工作，真正添加是doaddtimer方法\n// doaddtimer adds t to the current P\u0026#39;s heap. // The caller must have locked the timers for pp. func doaddtimer(pp *p, t *timer) { // Timers依赖network poller，确保netpoll经初始化了 // Timers rely on the network poller, so make sure the poller // has started. if netpollInited == 0 { netpollGenericInit() } if t.pp != 0 { // 创建timer时没有绑定p，如果p存在的话属于异常情况 throw(\u0026#34;doaddtimer: P already set in timer\u0026#34;) } t.pp.set(pp) // timer绑定到当前P的堆上 i := len(pp.timers) pp.timers = append(pp.timers, t) siftupTimer(pp.timers, i) // 调整4叉堆 if t == pp.timers[0] { // 如果新加入的timer是当前p中最新触发的，将t.when保存到pp.timer0When atomic.Store64(\u0026amp;pp.timer0When, uint64(t.when)) } atomic.Xadd(\u0026amp;pp.numTimers, 1) } doaddtimer方法中判断了netpoll是否初始化了，如果没有对其进行初始化，这里我还没有理解timer和netpoll之间的关系，作为todo，后续再补充\n后面就是p的timer之间的绑定，添加到四叉堆，然后平衡四叉堆，这里就不细说了\ndoaddtimer方法返回后，回到addtimer方法会调用wakeNetPoller方法\n// wakeNetPoller wakes up the thread sleeping in the network poller if it isn\u0026#39;t // going to wake up before the when argument; or it wakes an idle P to service // timers and the network poller if there isn\u0026#39;t one already. func wakeNetPoller(when int64) { if atomic.Load64(\u0026amp;sched.lastpoll) == 0 { // In findrunnable we ensure that when polling the pollUntil // field is either zero or the time to which the current // poll is expected to run. This can have a spurious wakeup // but should never miss a wakeup. pollerPollUntil := int64(atomic.Load64(\u0026amp;sched.pollUntil)) if pollerPollUntil == 0 || pollerPollUntil \u0026gt; when { // 网络轮询器poll \u0026gt; timer的触发时间，立即唤醒netpoll netpollBreak() } } else { // There are no threads in the network poller, try to get // one there so it can handle new timers. if GOOS != \u0026#34;plan9\u0026#34; { // Temporary workaround - see issue #42303. wakep() } } } // netpollBreak interrupts a kevent. func netpollBreak() { if atomic.Cas(\u0026amp;netpollWakeSig, 0, 1) { for { var b byte n := write(netpollBreakWr, unsafe.Pointer(\u0026amp;b), 1) if n == 1 || n == -_EAGAIN { break } if n == -_EINTR { continue } println(\u0026#34;runtime: netpollBreak write failed with\u0026#34;, -n) throw(\u0026#34;runtime: netpollBreak write failed\u0026#34;) } } } wakeNetPoller方法其实就是向netpoll初始化的全局epfd文件描述符写入了数据（epfd和golang netpoll有关，想了解netpoll的请自行了解）。主要目的是为了唤醒netpoll\n停止timer 可以通过Ticker#Stop和Timer#Stop停止timer\n// Stop prevents the Timer from firing. // It returns true if the call stops the timer, false if the timer has already // expired or been stopped. // Stop does not close the channel, to prevent a read from the channel succeeding // incorrectly. // // To ensure the channel is empty after a call to Stop, check the // return value and drain the channel. // For example, assuming the program has not received from t.C already: // // if !t.Stop() { // \u0026lt;-t.C // } // // This cannot be done concurrent to other receives from the Timer\u0026#39;s // channel or other calls to the Timer\u0026#39;s Stop method. // // For a timer created with AfterFunc(d, f), if t.Stop returns false, then the timer // has already expired and the function f has been started in its own goroutine; // Stop does not wait for f to complete before returning. // If the caller needs to know whether f is completed, it must coordinate // with f explicitly. func (t *Timer) Stop() bool { if t.r.f == nil { panic(\u0026#34;time: Stop called on uninitialized Timer\u0026#34;) } return stopTimer(\u0026amp;t.r) } // Stop turns off a ticker. After Stop, no more ticks will be sent. // Stop does not close the channel, to prevent a concurrent goroutine // reading from the channel from seeing an erroneous \u0026#34;tick\u0026#34;. func (t *Ticker) Stop() { stopTimer(\u0026amp;t.r) } 最后都是调用runtime.stopTimer方法；通过//go:linkname进行关联\n// stopTimer stops a timer. // It reports whether t was stopped before being run. //go:linkname stopTimer time.stopTimer func stopTimer(t *timer) bool { return deltimer(t) } // 返回的是这个timer在执行前被移除的，已经执行过了就返回false，还没有执行就返回true // deltimer deletes the timer t. It may be on some other P, so we can\u0026#39;t // actually remove it from the timers heap. We can only mark it as deleted. // It will be removed in due course by the P whose heap it is on. // Reports whether the timer was removed before it was run. func deltimer(t *timer) bool { for { switch s := atomic.Load(\u0026amp;t.status); s { case timerWaiting, timerModifiedLater: // timer还没启动或修改为更晚的时间 // Prevent preemption while the timer is in timerModifying. // This could lead to a self-deadlock. See #38070. mp := acquirem() // timerWaiting/timerModifiedLater --\u0026gt; timerModifying --\u0026gt; timerDeleted if atomic.Cas(\u0026amp;t.status, s, timerModifying) { // TODO 为什么要先切换为timerModifying // Must fetch t.pp before changing status, // as cleantimers in another goroutine // can clear t.pp of a timerDeleted timer. tpp := t.pp.ptr() if !atomic.Cas(\u0026amp;t.status, timerModifying, timerDeleted) { // 置为timerDeleted状态 badTimer() } releasem(mp) atomic.Xadd(\u0026amp;tpp.deletedTimers, 1) // Timer was not yet run. return true } else { // 修改为timerModifying失败，说明t的状态已经不再是timerWaiting, timerModifiedLater了 releasem(mp) // 下一次再来处理 } case timerModifiedEarlier: // Prevent preemption while the timer is in timerModifying. // This could lead to a self-deadlock. See #38070. mp := acquirem() // timerModifiedEarlier --\u0026gt; timerModifying --\u0026gt; timerDeleted if atomic.Cas(\u0026amp;t.status, s, timerModifying) { // Must fetch t.pp before setting status // to timerDeleted. tpp := t.pp.ptr() atomic.Xadd(\u0026amp;tpp.adjustTimers, -1) // timerModifiedEarlier的timer被stop了，所以需要将adjustTimers-1 if !atomic.Cas(\u0026amp;t.status, timerModifying, timerDeleted) { badTimer() } releasem(mp) atomic.Xadd(\u0026amp;tpp.deletedTimers, 1) // Timer was not yet run. return true } else { releasem(mp) // 下一次再来处理 } case timerDeleted, timerRemoving, timerRemoved: // Timer was already run. // Timer 已经运行 return false case timerRunning, timerMoving: // 正在执行或被移动了，等待完成，下一次再来处理 // The timer is being run or moved, by a different P. // Wait for it to complete. osyield() case timerNoStatus: // Removing timer that was never added or // has already been run. Also see issue 21874. return false case timerModifying: // 同时调用了deltimer，modtimer；等待其他调用完成，下一次再来处理 // Simultaneous calls to deltimer and modtimer. // Wait for the other call to complete. osyield() default: badTimer() } } } 从deltimer方法中可以看出，timer会发生如下的状态变化\ntimerWaiting, timerModifiedLater → timerModifying → timerDeleted\n如果要停止的timer状态是timerWaiting, timerModifiedLater，说明timer还没有执行，将状态切换成timerModifying改变中，最后将状态切换成timerDeleted\ntimerModifiedEarlier → timerModifying \u0026ndash;\u0026gt; timerDeleted\n如果要停止的timer状态是timerModifiedEarlier，说明timer的时间被改变过，比如reset过，将状态切换成timerModifying改变中，最后将状态切换成timerDeleted\ntimerDeleted, timerRemoving, timerRemoved → 什么都不做\ntimerRunning, timerMoving → 等待操作完成\ntimerNoStatus → 直接返回\ntimerModifying → 等待操作完成\n我在这里有2个问题\n为什么timer状态变化的时候需要需要先改为timerModifying然后再修改成最后的状态？\n答：首先声明这个只是我个人的理解可能会存在错误；在timer的status状态常量这有这么一段注释\n// We don\u0026#39;t permit calling addtimer/deltimer/modtimer/resettimer simultaneously, // but adjusttimers and runtimer can be called at the same time as any of those. 为了保证addtimer/deltimer/modtimer/resettimer不能被同时调用，所以需要timerModifying这个状态\ndeltimer并没有从 四叉堆中删除timer，只是将timer的状态切换成timerDeleted，这个是为什么？\n这个在deltimer的注释上已经说明了\n// deltimer deletes the timer t. It may be on some other P, so we can\u0026#39;t // actually remove it from the timers heap. We can only mark it as deleted. // It will be removed in due course by the P whose heap it is on. deltimer删除的timer可能在其他P上，以为调度循环的 时候不仅会从其他P上偷G，还会偷timer，所以只是对timer进行标记，在timer所在的P中，通过 cleantimers/adjusttimers等方法来真正从堆中删除\n其他timer的方法 分析了2个timer的方法后，就不再逐个看其他的方法了，大概都差不多，都是对timers堆中的timer状态进行修改，timers的调整等\n修改timer // modtimer modifies an existing timer. // This is called by the netpoll code or time.Ticker.Reset or time.Timer.Reset. // Reports whether the timer was modified before it was run. func modtimer(t *timer, when, period int64, f func(interface{}, uintptr), arg interface{}, seq uintptr) bool { if when \u0026lt;= 0 { throw(\u0026#34;timer when must be positive\u0026#34;) } if period \u0026lt; 0 { throw(\u0026#34;timer period must be non-negative\u0026#34;) } status := uint32(timerNoStatus) wasRemoved := false var pending bool var mp *m loop: for { switch status = atomic.Load(\u0026amp;t.status); status { case timerWaiting, timerModifiedEarlier, timerModifiedLater: // Prevent preemption while the timer is in timerModifying. // This could lead to a self-deadlock. See #38070. mp = acquirem() // timerWaiting, timerModifiedEarlier, timerModifiedLater --\u0026gt; timerModifying if atomic.Cas(\u0026amp;t.status, status, timerModifying) { pending = true // timer not yet run break loop } releasem(mp) case timerNoStatus, timerRemoved: // Prevent preemption while the timer is in timerModifying. // This could lead to a self-deadlock. See #38070. mp = acquirem() // Timer was already run and t is no longer in a heap. // Act like addtimer. // timerNoStatus, timerRemoved --\u0026gt; timerModifying if atomic.Cas(\u0026amp;t.status, status, timerModifying) { wasRemoved = true pending = false // timer already run or stopped break loop } releasem(mp) case timerDeleted: // Prevent preemption while the timer is in timerModifying. // This could lead to a self-deadlock. See #38070. mp = acquirem() // timerDeleted --\u0026gt; timerModifying if atomic.Cas(\u0026amp;t.status, status, timerModifying) { atomic.Xadd(\u0026amp;t.pp.ptr().deletedTimers, -1) pending = false // timer already stopped break loop } releasem(mp) case timerRunning, timerRemoving, timerMoving: // The timer is being run or moved, by a different P. // Wait for it to complete. osyield() // 等待状态改变 case timerModifying: // Multiple simultaneous calls to modtimer. // Wait for the other call to complete. osyield() // 等待状态改变 default: badTimer() } } t.period = period t.f = f t.arg = arg t.seq = seq if wasRemoved { t.when = when pp := getg().m.p.ptr() lock(\u0026amp;pp.timersLock) doaddtimer(pp, t) unlock(\u0026amp;pp.timersLock) if !atomic.Cas(\u0026amp;t.status, timerModifying, timerWaiting) { badTimer() } releasem(mp) wakeNetPoller(when) } else { // The timer is in some other P\u0026#39;s heap, so we can\u0026#39;t change // the when field. If we did, the other P\u0026#39;s heap would // be out of order. So we put the new when value in the // nextwhen field, and let the other P set the when field // when it is prepared to resort the heap. t.nextwhen = when newStatus := uint32(timerModifiedLater) if when \u0026lt; t.when { newStatus = timerModifiedEarlier } tpp := t.pp.ptr() // Update the adjustTimers field. Subtract one if we // are removing a timerModifiedEarlier, add one if we // are adding a timerModifiedEarlier. adjust := int32(0) if status == timerModifiedEarlier { adjust-- } if newStatus == timerModifiedEarlier { adjust++ updateTimerModifiedEarliest(tpp, when) } if adjust != 0 { atomic.Xadd(\u0026amp;tpp.adjustTimers, adjust) } // Set the new status of the timer. if !atomic.Cas(\u0026amp;t.status, timerModifying, newStatus) { badTimer() } releasem(mp) // If the new status is earlier, wake up the poller. if newStatus == timerModifiedEarlier { wakeNetPoller(when) } } return pending } 调整timer // 与cleantimers类似，只是 cleantimers 只处理队列头部的timer // adjusttimers looks through the timers in the current P\u0026#39;s heap for // any timers that have been modified to run earlier, and puts them in // the correct place in the heap. While looking for those timers, // it also moves timers that have been modified to run later, // and removes deleted timers. The caller must have locked the timers for pp. func adjusttimers(pp *p, now int64) { if atomic.Load(\u0026amp;pp.adjustTimers) == 0 { if verifyTimers { verifyTimerHeap(pp) } // There are no timers to adjust, so it is safe to clear // timerModifiedEarliest. Do so in case it is stale. // Everything will work if we don\u0026#39;t do this, // but clearing here may save future calls to adjusttimers. atomic.Store64(\u0026amp;pp.timerModifiedEarliest, 0) return } // If we haven\u0026#39;t yet reached the time of the first timerModifiedEarlier // timer, don\u0026#39;t do anything. This speeds up programs that adjust // a lot of timers back and forth if the timers rarely expire. // We\u0026#39;ll postpone looking through all the adjusted timers until // one would actually expire. if first := atomic.Load64(\u0026amp;pp.timerModifiedEarliest); first != 0 { if int64(first) \u0026gt; now { if verifyTimers { verifyTimerHeap(pp) } return } // We are going to clear all timerModifiedEarlier timers. atomic.Store64(\u0026amp;pp.timerModifiedEarliest, 0) } var moved []*timer loop: for i := 0; i \u0026lt; len(pp.timers); i++ { t := pp.timers[i] if t.pp.ptr() != pp { throw(\u0026#34;adjusttimers: bad p\u0026#34;) } switch s := atomic.Load(\u0026amp;t.status); s { case timerDeleted: if atomic.Cas(\u0026amp;t.status, s, timerRemoving) { dodeltimer(pp, i) if !atomic.Cas(\u0026amp;t.status, timerRemoving, timerRemoved) { badTimer() } atomic.Xadd(\u0026amp;pp.deletedTimers, -1) // Look at this heap position again. i-- } case timerModifiedEarlier, timerModifiedLater: if atomic.Cas(\u0026amp;t.status, s, timerMoving) { // Now we can change the when field. t.when = t.nextwhen // Take t off the heap, and hold onto it. // We don\u0026#39;t add it back yet because the // heap manipulation could cause our // loop to skip some other timer. dodeltimer(pp, i) moved = append(moved, t) if s == timerModifiedEarlier { if n := atomic.Xadd(\u0026amp;pp.adjustTimers, -1); int32(n) \u0026lt;= 0 { break loop } } // Look at this heap position again. i-- } case timerNoStatus, timerRunning, timerRemoving, timerRemoved, timerMoving: badTimer() case timerWaiting: // OK, nothing to do. case timerModifying: // Check again after modification is complete. osyield() i-- default: badTimer() } } if len(moved) \u0026gt; 0 { addAdjustedTimers(pp, moved) } if verifyTimers { verifyTimerHeap(pp) } } 运行timer // runtimer 检查timers四叉堆顶部的timer // runtimer examines the first timer in timers. If it is ready based on now, // it runs the timer and removes or updates it. // Returns 0 if it ran a timer, -1 if there are no more timers, or the time // when the first timer should run. // The caller must have locked the timers for pp. // If a timer is run, this will temporarily unlock the timers. //go:systemstack func runtimer(pp *p, now int64) int64 { for { t := pp.timers[0] if t.pp.ptr() != pp { throw(\u0026#34;runtimer: bad p\u0026#34;) } switch s := atomic.Load(\u0026amp;t.status); s { case timerWaiting: if t.when \u0026gt; now { // 还没到时间执行 // Not ready to run. return t.when } // 该执行这个timer了 if !atomic.Cas(\u0026amp;t.status, s, timerRunning) { continue } // Note that runOneTimer may temporarily unlock // pp.timersLock. runOneTimer(pp, t, now) return 0 case timerDeleted: // 删除已经执行了的timer if !atomic.Cas(\u0026amp;t.status, s, timerRemoving) { continue } dodeltimer0(pp) if !atomic.Cas(\u0026amp;t.status, timerRemoving, timerRemoved) { badTimer() } atomic.Xadd(\u0026amp;pp.deletedTimers, -1) if len(pp.timers) == 0 { return -1 } case timerModifiedEarlier, timerModifiedLater: // 调整timerModifiedEarlier, timerModifiedLater timer的时间 if !atomic.Cas(\u0026amp;t.status, s, timerMoving) { continue } t.when = t.nextwhen dodeltimer0(pp) doaddtimer(pp, t) if s == timerModifiedEarlier { atomic.Xadd(\u0026amp;pp.adjustTimers, -1) } if !atomic.Cas(\u0026amp;t.status, timerMoving, timerWaiting) { badTimer() } case timerModifying: // Wait for modification to complete. osyield() // 等到其他操作结束 case timerNoStatus, timerRemoved: // Should not see a new or inactive timer on the heap. badTimer() case timerRunning, timerRemoving, timerMoving: // These should only be set when timers are locked, // and we didn\u0026#39;t do it. badTimer() default: badTimer() } } } 触发timer 前面介绍的都是将 timer加入到 堆中，从堆中删除这些，那么timer时间到了，是怎么触发的呢？\n触发timer一定会执行前面所说的runtimer方法，可以发现runtimer是在checkTimers方法中被调用的\n// checkTimers runs any timers for the P that are ready. // If now is not 0 it is the current time. // It returns the current time or 0 if it is not known, // and the time when the next timer should run or 0 if there is no next timer, // and reports whether it ran any timers. // If the time when the next timer should run is not 0, // it is always larger than the returned time. // We pass now in and out to avoid extra calls of nanotime. //go:yeswritebarrierrec func checkTimers(pp *p, now int64) (rnow, pollUntil int64, ran bool) { // If it\u0026#39;s not yet time for the first timer, or the first adjusted // timer, then there is nothing to do. next := int64(atomic.Load64(\u0026amp;pp.timer0When)) nextAdj := int64(atomic.Load64(\u0026amp;pp.timerModifiedEarliest)) if next == 0 || (nextAdj != 0 \u0026amp;\u0026amp; nextAdj \u0026lt; next) { next = nextAdj } if next == 0 { // 没有timer需要执行和调整 // No timers to run or adjust. return now, 0, false } if now == 0 { now = nanotime() } if now \u0026lt; next { // 最快的 timer还没到 执行的时间 // Next timer is not ready to run, but keep going // if we would clear deleted timers. // This corresponds to the condition below where // we decide whether to call clearDeletedTimers. if pp != getg().m.p.ptr() || int(atomic.Load(\u0026amp;pp.deletedTimers)) \u0026lt;= int(atomic.Load(\u0026amp;pp.numTimers)/4) { return now, next, false } } lock(\u0026amp;pp.timersLock) if len(pp.timers) \u0026gt; 0 { adjusttimers(pp, now) // 删除已经执行的timer，调整timerModifiedEarlier 和 timerModifiedLater 的计时器的时间 for len(pp.timers) \u0026gt; 0 { // 执行所有到期的timer // Note that runtimer may temporarily unlock // pp.timersLock. if tw := runtimer(pp, now); tw != 0 { if tw \u0026gt; 0 { pollUntil = tw } break } ran = true } } // If this is the local P, and there are a lot of deleted timers, // clear them out. We only do this for the local P to reduce // lock contention on timersLock. // 当前 Goroutine 的处理器和传入的处理器相同,并且处理器中删除的计时器是堆中计时器的 1/4 以上， if pp == getg().m.p.ptr() \u0026amp;\u0026amp; int(atomic.Load(\u0026amp;pp.deletedTimers)) \u0026gt; len(pp.timers)/4 { clearDeletedTimers(pp) } unlock(\u0026amp;pp.timersLock) return now, pollUntil, ran } 而checkTimers在findrunnable和schedule中被调用，而这2个方法都是runtime调度会执行的方法（PS：runtime调度也是一个很重要的知识点，有兴趣的可以自行了解）\n除了runtime调度时会执行timer外，系统监控sysmon也会执行timer，其实这里我没有理解，所以这里直接用draveness大佬文章中的说明\n系统监控函数 runtime.sysmon 也可能会触发函数的计时器，下面的代码片段中省略了大量与计时器无关的代码：\nfunc sysmon() { ... for { ... now := nanotime() next, _ := timeSleepUntil() ... lastpoll := int64(atomic.Load64(\u0026amp;sched.lastpoll)) if netpollinited() \u0026amp;\u0026amp; lastpoll != 0 \u0026amp;\u0026amp; lastpoll+10*1000*1000 \u0026lt; now { atomic.Cas64(\u0026amp;sched.lastpoll, uint64(lastpoll), uint64(now)) list := netpoll(0) if !list.empty() { incidlelocked(-1) injectglist(\u0026amp;list) incidlelocked(1) } } if next \u0026lt; now { startm(nil, false) } ... } 调用 [runtime.timeSleepUntil](https://draveness.me/golang/tree/runtime.timeSleepUntil) 获取计时器的到期时间以及持有该计时器的堆； 如果超过 10ms 的时间没有轮询，调用 [runtime.netpoll](https://draveness.me/golang/tree/runtime.netpoll) 轮询网络； 如果当前有应该运行的计时器没有执行，可能存在无法被抢占的处理器，这时我们应该启动新的线程处理计时器； 在上述过程中 [runtime.timeSleepUntil](https://draveness.me/golang/tree/runtime.timeSleepUntil) 会遍历运行时的全部处理器并查找下一个需要执行的计时器。\n遗留问题 最后是我还存在的问题\nsysmon中为什么会触发timer\naddtimer方法中调用了wakeNetPoller(when)方法唤醒netpoll，但是netpoll()方法中对netpollBreakRd的处理并没有发现与timer有啥关系\n// netpoll checks for ready network connections. // Returns list of goroutines that become runnable. // delay \u0026lt; 0: blocks indefinitely // delay == 0: does not block, just polls // delay \u0026gt; 0: block for up to that many nanoseconds // delay \u0026lt; 0 无限block等待 // delay == 0 不会block // delay block 最多delay时间 // runtime.netpoll 返回的 Goroutine 列表都会被 runtime.injectglist 注入到处理器或者全局的运行队列上。 // 因为系统监控 Goroutine 直接运行在线程上，所以它获取的 Goroutine 列表会直接加入全局的运行队列， // 其他 Goroutine 获取的列表都会加入 Goroutine 所在处理器的运行队列上。 func netpoll(delay int64) gList { if epfd == -1 { // 没有epfd 相当于netpoll没有初始化 return gList{} } var waitms int32 if delay \u0026lt; 0 { waitms = -1 } else if delay == 0 { waitms = 0 } else if delay \u0026lt; 1e6 { waitms = 1 } else if delay \u0026lt; 1e15 { waitms = int32(delay / 1e6) } else { // An arbitrary cap on how long to wait for a timer. // 1e9 ms == ~11.5 days. waitms = 1e9 } var events [128]epollevent retry: // 等待文件描述符转换成可读或者可写 n := epollwait(epfd, \u0026amp;events[0], int32(len(events)), waitms) if n \u0026lt; 0 { // 如果返回了负值，可能会返回空的 Goroutine 列表或者重新调用 epollwait 陷入等待： if n != -_EINTR { println(\u0026#34;runtime: epollwait on fd\u0026#34;, epfd, \u0026#34;failed with\u0026#34;, -n) throw(\u0026#34;runtime: netpoll failed\u0026#34;) } // If a timed sleep was interrupted, just return to // recalculate how long we should sleep now. if waitms \u0026gt; 0 { return gList{} } goto retry } // 当 epollwait 系统调用返回的值大于 0 时，意味着被监控的文件描述符出现了待处理的事件 var toRun gList for i := int32(0); i \u0026lt; n; i++ { ev := \u0026amp;events[i] if ev.events == 0 { continue } // runtime.netpollBreak 触发的事件 if *(**uintptr)(unsafe.Pointer(\u0026amp;ev.data)) == \u0026amp;netpollBreakRd { if ev.events != _EPOLLIN { println(\u0026#34;runtime: netpoll: break fd ready for\u0026#34;, ev.events) throw(\u0026#34;runtime: netpoll: break fd ready for something unexpected\u0026#34;) } if delay != 0 { // netpollBreak could be picked up by a // nonblocking poll. Only read the byte // if blocking. var tmp [16]byte read(int32(netpollBreakRd), noescape(unsafe.Pointer(\u0026amp;tmp[0])), int32(len(tmp))) atomic.Store(\u0026amp;netpollWakeSig, 0) } continue } // 另一种是其他文件描述符的正常读写事件 var mode int32 if ev.events\u0026amp;(_EPOLLIN|_EPOLLRDHUP|_EPOLLHUP|_EPOLLERR) != 0 { mode += \u0026#39;r\u0026#39; } if ev.events\u0026amp;(_EPOLLOUT|_EPOLLHUP|_EPOLLERR) != 0 { mode += \u0026#39;w\u0026#39; } if mode != 0 { pd := *(**pollDesc)(unsafe.Pointer(\u0026amp;ev.data)) pd.everr = false if ev.events == _EPOLLERR { pd.everr = true } netpollready(\u0026amp;toRun, pd, mode) } } return toRun } draveness大佬文章的评论中也有人提到这个疑问，但是还是未能理解，我也加入 了讨论，期待后续的解答\n参考资料 6.3 计时器 Go中定时器实现原理及源码解析 难以驾驭的 Go timer，一文带你参透计时器的奥秘 go1.14基于netpoll优化timer定时器实现原理 https://www.youtube.com/watch?v=XJx0eTP-y9I ","permalink":"https://carlos19960601.github.io/posts/timer%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/","summary":"\u003cp\u003e根据\u003ca href=\"https://draveness.me/golang/docs/part3-runtime/ch06-concurrency/golang-timer/\"\u003e6.3 计时器\u003c/a\u003e中的描述，Golang Timer的设计经历了如下阶段：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eGo 1.9 版本之前，所有的计时器由全局唯一的四叉堆维护；\u003c/li\u003e\n\u003cli\u003eGo 1.10 ~ 1.13，全局使用 64 个四叉堆维护全部的计时器，每个处理器（P）创建的计时器会由对应的四叉堆维护；\u003c/li\u003e\n\u003cli\u003eGo 1.14 版本之后，每个处理器单独管理计时器并通过网络轮询器触发；\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003eGo 1.9 版本之前由于使用全局的四叉堆，在多核情况下会出现锁竞争导致性能问题\u003c/li\u003e\n\u003cli\u003eGo 1.10 ~ 1.13使用了64个四叉堆，有每个P来维护对应的四叉堆，相当于将锁的粒度减小，但是当timer在未到时间和到时间需要执行进行切换的时候，会发生P和M的绑定和解绑，尤其是当timer触发时间间隔比较小的情况下，会导致CPU占用过高，M/P切换的开销增加(TODO  为什么会发生P和M的绑定和解绑)\u003c/li\u003e\n\u003cli\u003eGo 1.14 版本后每个P管理计时器四叉堆，由网络轮询器和调度器进行触发\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e我使用的是Go 1.16的版本进行分析\u003c/p\u003e","title":"Timer源码阅读"},{"content":"线程池是什么？ 线程池用于多线程处理中，它可以根据系统的情况，可以有效控制线程执行的数量，优化运行效果。线程池做的工作主要是控制运行的线程的数量，处理过程中将任务放入队列，然后在线程创建后启动这些任务，如果线程数量超过了最大数量超出数量的线程排队等候，等其它线程执行完毕，再从队列中取出任务来执行。\n线程池的作用 在面向对象的编程过程中，创建对象和销毁对象是非常消耗时间和资源的。因此想要最小化这种消耗的一种思想就是『池化资源』。线程池就是这样的一种思想。我们通过重用线程池中的资源来减少创建和销毁线程所需要耗费的时间和资源。\n线程池的一个作用是创建和销毁线程的次数，每个工作线程可以多次使用；另一个作用是可根据系统情况调整执行的线程数量，防止消耗过多内存。另外，通过线程池，能有效的控制线程的最大并发数，提高系统资源利用率，同时避免过多的资源竞争，避免堵塞。\n线程池的优点总结如下几个方面：\n线程复用 控制最大并发数 管理线程 线程池的组成 一般的线程池主要分为以下4个组成部分：\n线程池管理器：用于创建并管理线程池 工作线程：线程池中的线程 任务接口：每个任务必须实现的接口，用于工作线程调度其运行 任务队列：用于存放待处理的任务，提供一种缓冲机制 线程池的常见应用场景 许多服务器应用常常需要处理大量而短小的请求（例如，Web 服务器，数据库服务器等等），通常它们收到的请求数量很大，一个简单的模型是，当服务器收到来自远程的请求时，为每一个请求开启一个线程，在请求完毕之后再对线程进行销毁。这样处理带来的问题是，创建和销毁线程所消耗的时间往往比任务本身所需消耗的资源要大得多。那么应该怎么办呢？\n线程池为线程生命周期开销问题和资源不足问题提供了解决方案。我们可以通过线程池做到线程复用，不需要频繁的创建和销毁线程，让线程池中的线程一直存在于线程池中，然后线程从任务队列中取得任务来执行。而且这样做的另一个好处有，通过适当地调整线程池中的线程数目，也就是当请求的数目超过某个阈值时，就强制其它任何新到的请求一直等待，直到获得一个线程来处理为止，从而可以防止资源不足。\nJava线程池的简介 Java中提供了实现线程池的框架Executor，并且提供了许多种类的线程池，接下来的文章中将会做详细介绍。\nJava线程池框架 Java中的线程池是通过Executor框架实现的，该框架中用到了Executor，Executors，ExecutorService，ThreadPoolExecutor ，Callable和Future、FutureTask这几个类。\nExecutor：所有线程池的接口，只有一个方法 Executors：Executor 的工厂类，提供了创建各种不同线程池的方法，返回的线程池都实现了ExecutorService 接口 ThreadPoolExecutor：线程池的具体实现类，一般所有的线程池都是基于这个类实现的 其中ThreadPoolExecutor的构造方法如下：\npublic ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue\u0026lt;Runnable\u0026gt; workQueue) { this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), defaultHandler); } 其中：\ncorePoolSize：线程池的核心线程数 maximumPoolSize：线程池中允许的最大线程数 keepAliveTime：空闲线程结束的超时时间 unit：是一个枚举，它表示的是 keepAliveTime 的单位 workQueue：工作队列，用于任务的存放 Java线程池的工作过程 Java线程池的工作过程如下：\n线程池刚创建时，里面没有一个线程。任务队列是作为参数传进来的。不过，就算队列里面有任务，线程池也不会马上执行它们。 当调用 execute() 方法添加一个任务时，线程池会做如下判断： 如果正在运行的线程数量小于 corePoolSize，那么马上创建线程运行这个任务； 如果正在运行的线程数量大于或等于 corePoolSize，那么将这个任务放入队列； 如果这时候队列满了，而且正在运行的线程数量小于 maximumPoolSize，那么还是要创建非核心线程立刻运行这个任务； 如果队列满了，而且正在运行的线程数量大于或等于 maximumPoolSize，那么线程池会抛出异常RejectExecutionException。 当一个线程完成任务时，它会从队列中取下一个任务来执行。 当一个线程无事可做，超过一定的时间（keepAliveTime）时，线程池会判断，如果当前运行的线程数大于 corePoolSize，那么这个线程就被停掉。所以线程池的所有任务完成后，它最终会收缩到 corePoolSize 的大小。 常见的Java线程池 生成线程池使用的是Executors的工厂方法，以下是常见的 Java 线程池：\nSingleThreadExecutor SingleThreadExecutor是单个线程的线程池，即线程池中每次只有一个线程在运行，单线程串行执行任务。如果这个唯一的线程因为异常结束，那么会有一个新的线程来替代它。此线程池保证所有任务的执行顺序按照任务的提交顺序执行。\npublic static ExecutorService newSingleThreadExecutor() { return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue\u0026lt;Runnable\u0026gt;())); } FixedThreadPool FixedThreadPool是固定数量的线程池，只有核心线程，每提交一个任务就是一个线程，直到达到线程池的最大数量，然后后面进入等待队列，直到前面的任务完成才继续执行。线程池的大小一旦达到最大值就会保持不变，如果某个线程因为执行异常而结束，那么线程池会补充一个新线程。\npublic static ExecutorService newFixedThreadPool(int nThreads) { return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue\u0026lt;Runnable\u0026gt;()); } CachedThreadPool CachedThreadPool是可缓存线程池。如果线程池的大小超过了处理任务所需要的线程，那么就会回收部分空闲（60秒不执行任务）的线程，当任务数增加时，此线程池又可以智能的添加新线程来处理任务。此线程池不会对线程池大小做限制，线程池大小完全依赖于操作系统（或者说JVM）能够创建的最大线程大小。其中，SynchronousQueue是一个是缓冲区为1的阻塞队列。\npublic static ExecutorService newCachedThreadPool() { return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue\u0026lt;Runnable\u0026gt;()); } ScheduledThreadPool ScheduledThreadPool是核心线程池固定，大小无限制的线程池，支持定时和周期性的执行线程。创建一个周期性执行任务的线程池。如果闲置,非核心线程池会在DEFAULT_KEEPALIVEMILLIS时间内回收。\npublic ScheduledThreadPoolExecutor(int corePoolSize) { super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue()); } Java 线程池的创建和使用 我们可以通过Executors的工厂方法来创建一个线程池。但是我们该如何让线程池执行任务呢？\n线程池最常用的提交任务的方法有两种：\nexecute： ExecutorService.execute(Runnable runable)； submit： FutureTask task = ExecutorService.submit(Runnable runnable); FutureTask\u0026lt;T\u0026gt; task = ExecutorService.submit(Runnable runnable,T Result); FutureTask\u0026lt;T\u0026gt; task = ExecutorService.submit(Callable\u0026lt;T\u0026gt; callable); 可以看出submit开启的是有返回结果的任务，会返回一个FutureTask对象，这样就能通过get()方法得到结果。submit最终调用的也是execute(Runnable runable)，submit只是将Callable对象或Runnable封装成一个FutureTask对象，因为FutureTask是个Runnable，所以可以在execute中执行。\n下面的示例代码演示了如何创建一个线程池，并且使用它管理线程：\npublic class MyThread extends Thread { @Override public void run() { System.out.println(Thread.currentThread().getName() + \u0026#34; is running.\u0026#34;); } } public class TestSingleThreadExecutor { public static void main(String[] args) { //创建一个可重用固定线程数的线程池 ExecutorService pool = Executors.newFixedThreadPool(2); //创建实现了Runnable接口对象 Thread tt1 = new MyThread(); Thread tt2 = new MyThread(); Thread tt3 = new MyThread(); Thread tt4 = new MyThread(); Thread tt5 = new MyThread(); //将线程放入池中并执行 pool.execute(tt1); pool.execute(tt2); pool.execute(tt3); pool.execute(tt4); pool.execute(tt5); //关闭 pool.shutdown(); } } 运行结果：\npool-1-thread-1 is running. pool-1-thread-2 is running. pool-1-thread-1 is running. pool-1-thread-2 is running. pool-1-thread-1 is running. Java线程池原理 这篇文章会分别从这三个方面，结合具体的代码实现来剖析 Java 线程池的原理以及它的具体实现。\n线程复用 我们知道线程池的一个作用是创建和销毁线程的次数，每个工作线程可以多次使用。这个功能就是线程复用。想要了解 Java 线程池是如何进行线程复用的，我们首先需要了解线程的生命周期。\n线程生命周期 下图描述了线程完整的生命周期：\n在一个线程完整的生命周期中，它可能经历五种状态：新建（New）、就绪（Runnable）、运行（Running）、阻塞（Blocked）、终止（Zombie）。\n在 Java中，Thread 通过new来新建一个线程，这个过程是是初始化一些线程信息，如线程名、id、线程所属group等，可以认为只是个普通的对象。调用Thread的start()后Java虚拟机会为其创建方法调用栈和程序计数器，同时将hasBeenStarted为true，之后如果再次调用start()方法就会有异常。\n处于这个状态中的线程并没有开始运行，只是表示该线程可以运行了。至于该线程何时开始运行，取决于 JVM 里线程调度器的调度。当线程获取CPU后，run()方法会被调用。不要自己去调用Thread的run()方法。之后根据CPU的调度，线程就会在就绪—运行—阻塞间切换，直到run()方法结束或其他方式停止线程，进入终止状态。\n因此，如果要实现线程的复用，我们必须要保证线程池中的线程保持存活状态（就绪、运行、阻塞）。接下来，我们就来看看ThreadPoolExecutor是如何实现线程复用的。\nWorker 类 ThreadPoolExecutor主要是通过一个类来控制线程复用的：Worker 类。\n我们来看一下简化后的 Worker 类代码：\nprivate final class Worker implements Runnable { final Thread thread; Runnable firstTask; Worker(Runnable firstTask) { this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this); } public void run() { runWorker(this); } final void runWorker(Worker w) { Runnable task = w.firstTask; w.firstTask = null; while (task != null || (task = getTask()) != null){ task.run(); } } …… } 从代码中，我们可以看到 Worker 实现了 Runnable 接口，并且它还有一个 Thread成员变量 thread，这个 thread 就是要开启运行的线程。我们看到 Worker 的构造方法中传递了一个 Runnable 参数，同时它把自己作为参数传入 newThread()，这样的话，当 Thread 的start()方法得到调用时，执行的其实是 Worker 的run()方法，即runWorker()方法。\nrunWorker()方法之中有一个 while 循环，使用 getTask()来获取任务，并执行。接下来，我们将会看到getTask()是如何获取到 Runnable 对象的。\ngetTask() 我们来看一下简化后的getTask()代码：\nprivate Runnable getTask() { if(一些特殊情况) { return null; } Runnable r = workQueue.take(); return r; } 我们可以看到任务是从 workQueue中获取的，这个 workQueue 就是我们初始化 ThreadPoolExecutor 时存放任务的 BlockingQueue队列，这个队列里的存放的都是将要执行的 Runnable任务。因为 BlockingQueue 是个阻塞队列，BlockingQueue.take()返回的是空，则进入等待状态直到 BlockingQueue 有新的对象被加入时唤醒阻塞的线程。所以一般情况下，Thread的run()方法不会结束，而是不断执行workQueue里的Runnable任务，这就达到了线程复用的目的了。\n控制最大并发数 我们现在已经知道了 Java 线程池是如何做到线程复用的了，但是Runnable 是什么时候被放入 workQueue 队列中的呢，Worker里的Thread的又是什么时候调用start()开启新线程来执行Worker的run()方法的呢？从上面的分析中我们可以看出Worker里的runWorker()执行任务时是一个接一个，串行进行的，那并发是怎么体现的呢？它又是如何做到控制最大并发数的呢？\nexecute() 通过查看 execute()就能解答上述的一些问题，同样是简化后的代码：\npublic void execute(Runnable command) { if (command == null) throw new NullPointerException(); int c = ctl.get(); // 当前线程数 \u0026lt; corePoolSize if (workerCountOf(c) \u0026lt; corePoolSize) { // 直接启动新的线程。 if (addWorker(command, true)) return; c = ctl.get(); } // 活动线程数 \u0026gt;= corePoolSize // runState为RUNNING \u0026amp;\u0026amp; 队列未满 if (isRunning(c) \u0026amp;\u0026amp; workQueue.offer(command)) { int recheck = ctl.get(); // 再次检验是否为RUNNING状态 // 非RUNNING状态 则从workQueue中移除任务并拒绝 if (!isRunning(recheck) \u0026amp;\u0026amp; remove(command)) reject(command); // 采用线程池指定的策略拒绝任务 // 两种情况： // 1.非RUNNING状态拒绝新的任务 // 2.队列满了启动新的线程失败（workCount \u0026gt; maximumPoolSize） } else if (!addWorker(command, false)) reject(command); } addWorker() 我们再来看一下addWorker()的简化代码：\nprivate boolean addWorker(Runnable firstTask, boolean core) { int wc = workerCountOf(c); if (wc \u0026gt;= (core ? corePoolSize : maximumPoolSize)) { return false; } w = new Worker(firstTask); final Thread t = w.thread; t.start(); } 根据上面的代码，线程池工作过程中是如何添加任务的就很清晰了：\n如果正在运行的线程数量小于 corePoolSize，那么马上创建线程运行这个任务； 如果正在运行的线程数量大于或等于 corePoolSize，那么将这个任务放入队列； 如果这时候队列满了，而且正在运行的线程数量小于 maximumPoolSize，那么还是要创建非核心线程立刻运行这个任务； 如果队列满了，而且正在运行的线程数量大于或等于 maximumPoolSize，那么线程池会抛出异常RejectExecutionException 如果通过addWorker()成功创建新的线程，则通过start()开启新线程，同时将firstTask作为这个Worker里的run()中执行的第一个任务。虽然每个Worker的任务是串行处理，但如果创建了多个Worker，因为共用一个workQueue，所以就会并行处理了。所以可以根据corePoolSize和maximumPoolSize来控制最大并发数。\n过程如下图所示：\n管理线程 上边的文章已经讲了，通过线程池可以很好的管理线程的复用，控制并发数，以及销毁等过程，而线程的管理过程已经穿插在其中了，也很好理解。\n在 ThreadPoolExecutor 有个AtomicInteger变量 ctl，这一个变量保存了两个内容：\n所有线程的数量 每个线程所处的状态 其中低29位存线程数，高3位存runState，通过位运算来得到不同的值。\nprivate final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0)); //得到线程的状态 private static int runStateOf(int c) { return c \u0026amp; ~CAPACITY; } //得到Worker的的数量 private static int workerCountOf(int c) { return c \u0026amp; CAPACITY; } // 判断线程是否在运行 private static boolean isRunning(int c) { return c \u0026lt; SHUTDOWN; } 这里主要通过shutdown和shutdownNow()来分析线程池的关闭过程。首先线程池有五种状态来控制任务添加与执行。主要介绍以下三种：\nRUNNING状态：线程池正常运行，可以接受新的任务并处理队列中的任务； SHUTDOWN状态：不再接受新的任务，但是会执行队列中的任务； STOP状态：不再接受新任务，不处理队列中的任务 shutdown()这个方法会将runState置为SHUTDOWN，会终止所有空闲的线程，而仍在工作的线程不受影响，所以队列中的任务人会被执行；shutdownNow()方法将runState置为STOP。和shutdown()方法的区别是，这个方法会终止所有的线程，所以队列中的任务也不会被执行了。\nJava线程池框架源码分析 前面的文章中已经给出了Java线程池框架中几个重要类的关系图:\n现在我们基于这张图来逐步分析。\nExecutor public interface Executor { void execute(Runnable command); } 这个接口表示向线程池中提交一个任务。\nExecutorService public interface ExecutorService extends Executor { void shutdown(); List\u0026lt;Runnable\u0026gt; shutdownNow(); boolean isShutdown(); boolean isTerminated(); boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException; \u0026lt;T\u0026gt; Future\u0026lt;T\u0026gt; submit(Callable\u0026lt;T\u0026gt; task); \u0026lt;T\u0026gt; Future\u0026lt;T\u0026gt; submit(Runnable task, T result); Future\u0026lt;?\u0026gt; submit(Runnable task); \u0026lt;T\u0026gt; List\u0026lt;Future\u0026lt;T\u0026gt;\u0026gt; invokeAll(Collection\u0026lt;? extends Callable\u0026lt;T\u0026gt;\u0026gt; tasks) throws InterruptedException; \u0026lt;T\u0026gt; List\u0026lt;Future\u0026lt;T\u0026gt;\u0026gt; invokeAll(Collection\u0026lt;? extends Callable\u0026lt;T\u0026gt;\u0026gt; tasks, long timeout, TimeUnit unit) throws InterruptedException; \u0026lt;T\u0026gt; T invokeAny(Collection\u0026lt;? extends Callable\u0026lt;T\u0026gt;\u0026gt; tasks) throws InterruptedException, ExecutionException; \u0026lt;T\u0026gt; T invokeAny(Collection\u0026lt;? extends Callable\u0026lt;T\u0026gt;\u0026gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException; } 可以看到 ExecutorService 扩展了 Executor 接口，在 Executor 基础上提供了更多的提交任务的方式和管理线程池的一些方法。\nAbstractExecutorService public abstract class AbstractExecutorService implements ExecutorService { } ThreadPoolExecutor ThreadPoolExecutor 是线程池框架的关键类. 首先来看一下 ThreadPoolExecutor 中几个重要的属性.\npublic class ThreadPoolExecutor extends AbstractExecutorService { /** * 整个线程池的状态控制类 ctl, 是一个 AtomicInteger ，封装了下面2个部分: * workerCount 表示有效的线程数 * runState 表示线程池当前状态，是running, shutdown还是其他状态 * * runState表示了线程池的整个整个生命周期，可以取以下值: * RUNNING: 接受新的task，处理队列中的task * SHUTDOWN: 不接受新的 task 但会处理队列中的 task * STOP: 不接受新的 task, 不处理队列中的 task, 中断正在执行的 task * TIDYING: 所有 task 执行结束, workerCount 是 0, 线程过渡到TIDYING会调用 terminated()钩子方法 * TERMINATED: terminated()执行完成 * * 状态转换关系: * * RUNNING -\u0026gt; SHUTDOWN(调用shutdown()) * On invocation of shutdown(), perhaps implicitly in finalize() * (RUNNING or SHUTDOWN) -\u0026gt; STOP(调用shutdownNow()) * On invocation of shutdownNow() * SHUTDOWN -\u0026gt; TIDYING(queue和pool均empty) * When both queue and pool are empty * TIDYING -\u0026gt; TERMINATED(调用terminated()) * When the terminated() hook method has completed */ private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0)); /** * task 的队列 */ private final BlockingQueue\u0026lt;Runnable\u0026gt; workQueue; /** * worker 线程的 Set, 只有持有 mainlock 时才能访问 */ private final ReentrantLock mainLock = new ReentrantLock(); private final HashSet\u0026lt;Worker\u0026gt; workers = new HashSet\u0026lt;Worker\u0026gt;(); private final Condition termination = mainLock.newCondition(); private int largestPoolSize; private long completedTaskCount; private volatile ThreadFactory threadFactory; private volatile RejectedExecutionHandler handler; /** * idle 线程waiting for work的超时时间 */ private volatile long keepAliveTime; /** * 如果是 false,core threads将会保持 alive 即使处于 idel 状态 * 如果是 true,core threads会keepAliveTime作为超时时间 wait for work */ private volatile boolean allowCoreThreadTimeOut; private volatile int corePoolSize; private volatile int maximumPoolSize; private static final RejectedExecutionHandler defaultHandler = new AbortPolicy(); } workerCount, runState 使用一个 AtomicInteger 进行了封装, runState用 int 的高3位标书,低位表示 workerCount, 所以我们能看到 ThreadPoolExecutor 中和 ctl 相关的常量和解析方法.\nprivate static final int COUNT_BITS = Integer.SIZE - 3; private static final int CAPACITY = (1 \u0026lt;\u0026lt; COUNT_BITS) - 1; // runState is stored in the high-order bits private static final int RUNNING = -1 \u0026lt;\u0026lt; COUNT_BITS; private static final int SHUTDOWN = 0 \u0026lt;\u0026lt; COUNT_BITS; private static final int STOP = 1 \u0026lt;\u0026lt; COUNT_BITS; private static final int TIDYING = 2 \u0026lt;\u0026lt; COUNT_BITS; private static final int TERMINATED = 3 \u0026lt;\u0026lt; COUNT_BITS; // Packing and unpacking ctl private static int runStateOf(int c) { return c \u0026amp; ~CAPACITY; } private static int workerCountOf(int c) { return c \u0026amp; CAPACITY; } private static int ctlOf(int rs, int wc) { return rs | wc; } ThreadPoolExecutor 最主要的构造函数,设置上面说的重要属性.\npublic ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue\u0026lt;Runnable\u0026gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) { if (corePoolSize \u0026lt; 0 || maximumPoolSize \u0026lt;= 0 || maximumPoolSize \u0026lt; corePoolSize || keepAliveTime \u0026lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler; } 现在来看一下 execute() 方法, execute()方法有3个处理步骤:\n线程数小于 corePoolSize 时,则试图创建一个新的 worker 线程 如果上面一步失败了，则试图将任务添加到阻塞队列中，并且要再一次判断需要不需要回滚队列，或者说创建线程 如果上面两步都失败了，则会试图强行创建一个线程来执行这个任务，如果还是失败，扔掉这个任务 public void execute(Runnable command) { if (command == null) throw new NullPointerException(); int c = ctl.get(); // 1.判断有效线程数是否小于核心线程数 if (workerCountOf(c) \u0026lt; corePoolSize) { //创建新线程 if (addWorker(command, true)) return; c = ctl.get(); } // 2.分开来看，首先判断当前的池子是否是处于 running 状态 // 因为只有 running 状态才可以接收新任务 // 接下来判断能否成功添加到队列中，如果队列满了或者其他情况则会跳到下一步 if (isRunning(c) \u0026amp;\u0026amp; workQueue.offer(command)) { int recheck = ctl.get(); // 再次检查池子的状态，如果进入了非 running 状态，回滚队列，扔掉这个任务 if (! isRunning(recheck) \u0026amp;\u0026amp; remove(command)) reject(command); //如果处于 running 状态则检查当前的有效线程，如果没有则创建一个线程 else if (workerCountOf(recheck) == 0) addWorker(null, false); } // 3.前两步失败了，就强行创建线程，成功会返回true，如果失败扔掉这个任务 else if (!addWorker(command, false)) reject(command); } 解释一下第二步，为什么要recheck\n当这个任务被添加到了阻塞队列前，池子处于 RUNNING 状态，但如果在添加到队列成功后，池子进入了 SHUTDOWN 状态或者其他状态，这时候是不应该再接收新的任务的，所以需要把这个任务从队列中移除，并且 reject\n同样，在没有添加到队列前，可能有一个有效线程，但添加完任务后，这个线程闲置超时或者因为异常被干掉了，这时候需要创建一个新的线程来执行任务\n为了更直观的理解一个任务的执行过程，可以参考下面这张图\naddWorker() 前一步把 execute 的流程捋了一遍，里面多次出现了 addWorker() 方法，前文说到这是个创建线程的方法，来看看 addWorker 做了些什么，这个方法代码比较长，我们拆开来一点一点看.\n第一部分 — 判断各种基础异常 private boolean addWorker(Runnable firstTask, boolean core) { retry: for (;;) { int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. // 检查线程池状态，队列状态，以及 firstask ，拆开来看 // 这段代码看起来异常的蛋疼,转换一下逻辑即 // rs\u0026gt;= SHUTDOWN \u0026amp;\u0026amp; (rs != SHUTDOWN || firstTask != null ||workQueue.isEmpty()) // 总结起来就是 当前处于非 Running 状态,并且这三种情况 // 1. 不是处于 SHUTDOWN 状态，不能再创建线程 // 2. 有新的任务 (因为不能再接收新的任务) // 3. 阻塞队列中已经没有任务 (不需要再创建线程) if (rs \u0026gt;= SHUTDOWN \u0026amp;\u0026amp; ! (rs == SHUTDOWN \u0026amp;\u0026amp; firstTask == null \u0026amp;\u0026amp; ! workQueue.isEmpty())) return false; for (;;) { //当前有效线程数目 int wc = workerCountOf(c); // 根据传入的参数确定以核心线程数还是最大线程数作为判断条件 if (wc \u0026gt;= CAPACITY || wc \u0026gt;= (core ? corePoolSize : maximumPoolSize)) // 大于容量 或者指定的线程数，不允许创建 return false; if (compareAndIncrementWorkerCount(c)) break retry; c = ctl.get(); // Re-read ctl if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop } } } 第二部分 — 试图创建线程 创建一个Worker\nboolean workerStarted = false; //标记 worker 开启状态 boolean workerAdded = false; //标记 worker 添加状态 Worker w = null; try { w = new Worker(firstTask); //将这个任务作为 worker 的第一个任务传入 final Thread t = w.thread; //通过 worker 获取到一个线程 if (t != null) { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int rs = runStateOf(ctl.get()); // running状态，或者 shutdown 状态但是没有新的任务 if (rs \u0026lt; SHUTDOWN || (rs == SHUTDOWN \u0026amp;\u0026amp; firstTask == null)) { if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); // 将这个 worker 添加到线程池中 workers.add(w); int s = workers.size(); if (s \u0026gt; largestPoolSize) largestPoolSize = s; // 标记worker添加成功 workerAdded = true; } } finally { mainLock.unlock(); } // 如果 worker 创建成功，开启线程 if (workerAdded) { t.start(); workerStarted = true; } } } finally { if (! workerStarted) addWorkerFailed(w); } return workerStarted; 上面代码从逻辑层面来看不算难懂，到这里一个任务到达后，ThreadPoolExecutor 的处理就结束了，那么任务又是怎么被添加到阻塞队列中，线程是如何从队列中取出任务，上文中的 Worker 又是什么东西？\n一个一个来，先来看看 Worker 到底是什么.\nWorker Worker 是 ThreadPoolExecutor 的一个内部类，实现了 Runnable 接口，继承自 AbstractQueuedSynchronizer,这又是个什么鬼？？? 这个就是经常见到的 AQS 的全称,这个暂时还没有研究.~~~~\nprivate final class Worker extends AbstractQueuedSynchronizer implements Runnable { final Thread thread; /** Initial task to run. Possibly null. */ Runnable firstTask; /** Per-thread task counter */ volatile long completedTasks; } 简单来说，Worker实现了 lock 和 unLock 方法来标示当前线程的状态是否为闲置\n// Lock methods // // The value 0 represents the unlocked state. // The value 1 represents the locked state. public void lock() { acquire(1); } public boolean tryLock() { return tryAcquire(1); } public void unlock() { release(1); } public boolean isLocked() { return isHeldExclusively(); } 上一节创建线程成功后调用 t.start() 而这个线程又是 Worker 的成员变量\nWorker(Runnable firstTask) { setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this); } 可以看到这里将 Worker 作为 Runnable 参数创建了一个新的线程，我们知道 Thread 接收一个 Runnable 对象后 start 运行的是 Runnable 的 run 方法，Worker 的 run 方法调用了 runWorker ,这个方法里面就是取出任务执行的逻辑\npublic void run() { runWorker(this); } final void runWorker(Worker w) { Thread wt = Thread.currentThread(); Runnable task = w.firstTask; // 获取到 worker 的第一个任务 w.firstTask = null; w.unlock(); // 标记为闲置，还没有开始任务 允许打断 boolean completedAbruptly = true; // 异常退出标记 try { // 循环取出任务，如果第一个任务不为空，或者从队列中拿到了任务 // 只要这两个条件满足，会一直循环，直到没有任务，正常退出，或者异常退出 while (task != null || (task = getTask()) != null) { w.lock();// 该线程标记为非闲置 // If pool is stopping, ensure thread is interrupted; // if not, ensure thread is not interrupted. This // requires a recheck in second case to deal with // shutdownNow race while clearing interrupt // 翻译注释：1.如果线程池STOPPING状态，需要中断线程 // 2.Thread.interrupted()是一个native方法，返回当前线程是否有被等待中断的请求 // 3.第二个条件成立时，检查线程池状态，如果为STOP，并且没有被中断，则中断线程 if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() \u0026amp;\u0026amp; runStateAtLeast(ctl.get(), STOP))) \u0026amp;\u0026amp; !wt.isInterrupted()) wt.interrupt(); // 执行任务 try { beforeExecute(wt, task);// 执行前 Throwable thrown = null; try { task.run(); // 执行任务 } catch (RuntimeException x) { thrown = x; throw x; } catch (Error x) { thrown = x; throw x; } catch (Throwable x) { thrown = x; throw new Error(x); } finally { afterExecute(task, thrown); // 执行结束 } } finally { task = null; // 将 worker 的任务置空 w.completedTasks++; w.unlock(); // 释放锁，进入闲置状态 } }// 循环结束 completedAbruptly = false; // 标记为正常退出 } finally { // 干掉 worker processWorkerExit(w, completedAbruptly); } } 这里弄清楚了一件事情，进入循环准备执行任务时，worker 加锁标记为非闲置，任务执行完毕或者出现异常，worker 释放锁，进入闲置状态。\n也就是当一个 worker 执行任务前或者执行完任务，到取出下一个任务期间，都是闲置状态可以被打断\n上面取出任务调用了 getTask() ，诶～为什么有一个死循环，别着急，慢慢看来。上面的代码可以知道如果 getTask 返回任务则执行，如果返回为 null 则 worker 需要被回收\nprivate Runnable getTask() { // 标记取任务是否超时 boolean timedOut = false; // Did the last poll() time out? for (;;) { int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. // 如果线程池状态为 STOP 或者 SHUTDOWN 并且队列已经为空，回收 wroker if (rs \u0026gt;= SHUTDOWN \u0026amp;\u0026amp; (rs \u0026gt;= STOP || workQueue.isEmpty())) { decrementWorkerCount(); return null; } //获取当前有效线程数 int wc = workerCountOf(c); // Are workers subject to culling? // timed 用来标记当前的 worker 是否设置超时时间， // 还记得获取线程池的时候 可以设置核心线程超时时间 //1.允许核心线程超时回收(即所有线程) 2.当前有效线程超过核心线程数(需要回收) // 如果timed == false 则该worker不会被回收，如果没有取到任务 会一直阻塞 boolean timed = allowCoreThreadTimeOut || wc \u0026gt; corePoolSize; // 回收线程条件 // 1. 有效线程数已经大于了线程池的最大线程数或者设置了超时回收并且已经超时 // 2. 有效线程数大于1或者队列任务已经为空 // 只有当上面1和2 同时满足时 则试图回收线程 if ((wc \u0026gt; maximumPoolSize || (timed \u0026amp;\u0026amp; timedOut)) \u0026amp;\u0026amp; (wc \u0026gt; 1 || workQueue.isEmpty())) { // 如果减少workercount成功 直接回收 if (compareAndDecrementWorkerCount(c)) return null; // 否则重走循环，从第一个判断条件处回收 continue; } // 取任务 try { // 根据是否设置超时回收来选择不同的取任务的方式 // poll 方法取任务会有超时时间，超过时间则返回null // take 方法没有超时时间，阻塞式方法 Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); // 如果任务不为空返回任务 if (r != null) return r; // 否则标记超时 进入下一次循环等待回收 timedOut = true; } catch (InterruptedException retry) { // 如果出现异常，试图重试 timedOut = false; } } } getTask() 方法逻辑也捋得差不多了，这里又出现了两个新的方法，workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) 和 workQueue.take() ，这两个都是阻塞队列的方法，来看看它们又各自是怎么实现的\nLinkedBlockingQueue — 阻塞队列 ThreadPoolExecutor 使用的是链表结构的阻塞队列，实现了 BlockingQueue 接口，而 BlockingQueue 则是继承自 Queue 接口，再上层就是 Collection 接口。\n因为本篇笔记主要是分析 ThreadPoolExecutor 的原理，所以不会详细介绍 LinkedBlockingQueue 中的其它代码，主要介绍这里所用的方法，首先来看一下上文所提到的 take()\npublic E take() throws InterruptedException { E x; // 任务 int c = -1; // 取出任务后的剩余任务数量 final AtomicInteger count = this.count; // 当前任务数量 final ReentrantLock takeLock = this.takeLock; // 加锁防止并发 takeLock.lockInterruptibly(); try { // 如果队列数量为空，则一直循环，阻塞线程 while (count.get() == 0) { notEmpty.await(); } // 取出任务 x = dequeue(); // 任务数量减一 c = count.getAndDecrement(); if (c \u0026gt; 1) notEmpty.signal();// 标记队列非空 } finally { takeLock.unlock(); // 释放锁 } if (c == capacity) signalNotFull();//标记队列已满 return x;// 返回任务 } 上面的代码可以知道 take 方法会一直阻塞直到队列有新的任务为止\n接下来是 poll 方法，可以看到几乎与 take 方法相同，唯一的区别是在阻塞的循环代码块里面加了时间判断，如果超时则直接返回为空，不会一直阻塞下去\npublic E poll(long timeout, TimeUnit unit) throws InterruptedException { E x = null; // 存放的任务 int c = -1; long nanos = unit.toNanos(timeout); // 超时时间 final AtomicInteger count = this.count; // 队列中的数量 final ReentrantLock takeLock = this.takeLock; // 加锁防止并发 takeLock.lockInterruptibly(); try { // 如果队列为空，则不断的循环 while (count.get() == 0) { // 如果当倒计时小于0 即超时时间到 则返回空 if (nanos \u0026lt;= 0) return null; // 让线程等待 nanos = notEmpty.awaitNanos(nanos); } x = dequeue(); // 取出一个任务 c = count.getAndDecrement(); // 取出后的队列数量 if (c \u0026gt; 1) notEmpty.signal(); // 标记非空 } finally { takeLock.unlock(); // 释放锁 } if (c == capacity) signalNotFull(); // 标记队列已满 return x; // 返回任务 } 线程池的回收及终止 前一节分析了任务的执行流程及原理，也留下了一个问题，worker 是如何被回收的呢？线程池该如何管理呢？回到上一节的 runWorker() 方法中，还记得最后调用了一个方法\nprocessWorkerExit(w, completedAbruptly); 这个方法传入了两个参数，第一个是当前的 Woker ,第二个是标记异常退出的标识\n首先判断是否为异常退出，如果是异常退出的话需要手动调整线程数量，如果是正常回收的，getTask 方法里面已经手动调整过了，不记得的小伙伴可以看看前文的代码，找找 decrementWorkerCount(),\nprivate void processWorkerExit(Worker w, boolean completedAbruptly) { if (completedAbruptly) // If abrupt, then workerCount wasn\u0026#39;t adjusted decrementWorkerCount(); // 加锁 final ReentrantLock mainLock = this.mainLock; mainLock.lock(); // 记录线程池完成的任务总数，从 workers 中移除该 worker try { completedTaskCount += w.completedTasks; workers.remove(w); } finally { mainLock.unlock(); } tryTerminate(); // 尝试关闭池子 int c = ctl.get(); // 以下的代码是判断需不需要给线程池创建一个新的线程 // 如果线程池的状态是 RUNNING 或者 SHUTDOWN 进一步判断需不需要创建 if (runStateLessThan(c, STOP)) { // 如果为异常退出直接创建，如果不是异常退出进入判断 if (!completedAbruptly) { // 获取线程池应该存在的最小线程数 如果设置了超时 则是0，否则是核心线程数 int min = allowCoreThreadTimeOut ? 0 : corePoolSize; // 如果 min 是0 但是队列又不为空，则 min 应该是1 if (min == 0 \u0026amp;\u0026amp; ! workQueue.isEmpty()) min = 1; //如果当前池中的有效线程数大于等于最小线程数 则不需要创建 if (workerCountOf(c) \u0026gt;= min) return; // replacement not needed } // 创建线程 addWorker(null, false); } } 上面的代码中调用了 tryTerminate() 方法，这个方法是用于终止线程池的，又是一个 for 循环，从代码结构来看是异常情况的重试机制。还是老方法，慢慢来看总共做了几件事情\nfinal void tryTerminate() { for (;;) { int c = ctl.get(); // 如果处于这三种情况不需要关闭线程池 // 1. Running 状态 // 2. SHUTDOWN 状态并且任务队列不为空，不能终止 // 3. TIDYING 或者 TERMINATE 状态，说明已经在关闭了 不需要重复关闭 if (isRunning(c) || runStateAtLeast(c, TIDYING) || (runStateOf(c) == SHUTDOWN \u0026amp;\u0026amp; ! workQueue.isEmpty())) return; // 进入到关闭线程池的代码，如果线程池中还有线程，则需要打断线程 if (workerCountOf(c) != 0) { // Eligible to terminate 可以关闭池子 // 打断闲置线程，只打断一个 interruptIdleWorkers(ONLY_ONE); return; // 如果有两个以上怎么办？只打断一个？ // 这里只打断一个是因为 worker 回收的时候都会进入到该方法中来，可以回去再看看 // runWorker方法最后的代码 } // 线程已经回收完毕，准备关闭线程池 final ReentrantLock mainLock = this.mainLock; mainLock.lock();// 加锁 try { // 将状态改变为 TIDYING 并且即将调用 terminated if (ctl.compareAndSet(c, ctlOf(TIDYING, 0))) { try { terminated(); // 终止线程池 } finally { ctl.set(ctlOf(TERMINATED, 0)); // 改变状态 termination.signalAll(); } return; } } finally { mainLock.unlock(); // 如果终止失败会重试 } // else retry on failed CAS } } 尝试终止线程池的代码分析完了，好像就结束了～但作为好奇宝宝，我们是不是应该看看如何打断闲置线程，以及 terminated 中做了什么呢？来吧，继续装逼\n先来看打断线程\nprivate void interruptIdleWorkers(boolean onlyOne) { final ReentrantLock mainLock = this.mainLock; mainLock.lock();//加锁～ try { // 遍历线程池中的 wroker for (Worker w : workers) { Thread t = w.thread; // 如果线程没有被中断，并且能够获取到 worker的锁(说明是闲置线程) if (!t.isInterrupted() \u0026amp;\u0026amp; w.tryLock()) { try { t.interrupt();// 中断线程 } catch (SecurityException ignore) { } finally { w.unlock(); } } // 只中断一个 worker 跳出循环，否则会将所有的闲置线程都中断 if (onlyOne) break; } } finally { mainLock.unlock();// 释放锁 } 有同学开始装逼了，说我们是好奇宝宝，t.interrupt() 方法也应该看，嗯～没错，但这里是调用了 native 方法，会 c 的可以去看看装逼，我就算了～\n好了，再来看看 terminate, 是不是很坑爹？ terminated 里面神！马！也！没！干！。。。淡定，其实这个方法类似于 Activity 的生命周期方法，允许你在被终止时做一些事情，默认的线程池没有什么要做的事情，当然什么也没写啦～\n/** * Method invoked when the Executor has terminated. Default * implementation does nothing. Note: To properly nest multiple * overridings, subclasses should generally invoke * {@code super.terminated} within this method. */ protected void terminated() { } 异常处理 还记得前面讲到，出现各种异常情况，添加队列失败等等，只是笼统的说了一句扔掉，当然代码实现不可能是简单一句扔掉就完了。回到 execute() 方法中找到 reject() 任务，看看究竟是怎么处理的\nfinal void reject(Runnable command) { handler.rejectedExecution(command, this); } 还记得在创建线程池的时候，初始化了一个 handler — RejectedExecutionHandler\n这是一个接口，只有一个方法,接收两个参数\nvoid rejectedExecution(Runnable r, ThreadPoolExecutor executor); 既然是一个接口，那么肯定有他的实现类，我们先不急着看所有实现类，先来看看这里的 handler 可能是什么，记得在使用 Executors 获取线程池调用构造方法的时候并没有传入 handler 参数，那么 ThreadPoolExecutor 应该会有一个默认的 handler\nprivate static final RejectedExecutionHandler defaultHandler = new AbortPolicy(); public static class AbortPolicy implements RejectedExecutionHandler { public AbortPolicy() { } public void rejectedExecution(Runnable r, ThreadPoolExecutor e) { throw new RejectedExecutionException(\u0026#34;Task \u0026#34; + r.toString() + \u0026#34; rejected from \u0026#34; + e.toString()); } } 默认 handler 是 AbortPolicy ,这个类实现了 rejectedExecution() 方法，抛了一个 Runtime 异常，也就是说当任务添加失败，就会抛出异常。这个类在 AsyncTask 引发了一场血案～所以在 API19 以后修改了 AsyncTask 的部分代码逻辑，这里就不细说啦.\n实际上，在 ThreadPoolExecutor 中除了 AbortPolicy 外还实现了三种不同类型的 handler\nCallerRunsPolicy — 在 线程池没有 shutdown 的前提下，会直接在执行 execute 方法的线程里执行这个任务 public void rejectedExecution(Runnable r, ThreadPoolExecutor e) { if (!e.isShutdown()) { r.run(); } } DiscardPolicy — 啥也不干，默默地丢掉任务～不信你看 public void rejectedExecution(Runnable r, ThreadPoolExecutor e) { } DiscardOldestPolicy — 丢弃掉队列中未执行的，最老的任务，也就是任务队列排头的任务，然后再试图在执行一次 public void rejectedExecution(Runnable r, ThreadPoolExecutor e) { if (!e.isShutdown()) { e.getQueue().poll(); e.execute(r); } } ","permalink":"https://carlos19960601.github.io/posts/java%E7%BA%BF%E7%A8%8B%E6%B1%A0/","summary":"\u003ch4 id=\"线程池是什么\"\u003e线程池是什么？\u003c/h4\u003e\n\u003cp\u003e线程池用于多线程处理中，它可以根据系统的情况，可以有效控制线程执行的数量，优化运行效果。线程池做的工作主要是控制运行的线程的数量，处理过程中将任务放入队列，然后在线程创建后启动这些任务，如果线程数量超过了最大数量超出数量的线程排队等候，等其它线程执行完毕，再从队列中取出任务来执行。\u003c/p\u003e","title":"Java线程池"},{"content":"前言 之前学习JVM垃圾回收时，主要是过了一遍垃圾收集算法，比如复制算法，标记-清除算法，标记-整理算法，在此基础上可以增加分代，每代采取不同的回收算法，以提高整体的分配和回收效率。然后过了一遍JVM中的垃圾收集器，比如Serial、Parallel Scavenge、Parallel New、CMS、G1等。\n自认为垃圾收集就是根据GC Root标记所有可达的对象，然后把所有没有标记的对象清除就ok了。是不是很简单。事实上垃圾收集也就是这么一回事，但是很多时候说起来简单，做起来却会出现很多问题。这篇文章就是记录我对CMS垃圾收集器的一些疑问并学习的过程。\n首先看一下CMS的整体流程(具体每个流程的详情就自行了解吧)\n如何进行标记？ 最近在看Golang的GC算法实现，里面用到了三色标记法，但是在我的知识库中对三色标记法有这个概念，是的，我只知道这个概念，不知道三色标记法是怎么一个流程，也不知道三色标记法在GC中怎么与运行的。于是就开始了我的探险之旅。\n在搜索了一下三色标记法（具体可以看一下文末参考文档中三色标记法与读写屏障了解详情）后，发现现代追踪式（可达性分析）的垃圾回收器几乎都借鉴了三色标记的算法思想，CMS垃圾收集器也不例外。\nGC Root有哪些？ 我们知道怎么进行标记了，但最初标记的时候需要一些根据才行啊，这些根据就是我们收的GC Root。GC Root有哪些？网上有很多的答案，我的理解就是\n当前活跃调用栈中的指向对象的引用 一些不会发生改变的数据所指向的引用 这里我使用的是引用，而不是对象，因为R大是这样说的（具体的问题见参考文档java的gc为什么要分代？）\n所谓“GC roots”，或者说tracing GC的“根集合”，就是一组必须活跃的引用。 例如说，这些引用可能包括：\n所有Java线程当前活跃的栈帧里指向GC堆里的对象的引用；换句话说，当前所有正在被调用的方法的引用类型的参数/局部变量/临时值。 VM的一些静态数据结构里指向GC堆里的对象的引用，例如说HotSpot VM里的Universe里有很多这样的引用。 JNI handles，包括global handles和local handles （看情况）所有当前被加载的Java类 （看情况）Java类的引用类型静态变量 （看情况）Java类的运行时常量池里的引用类型常量（String或Class类型） （看情况）String常量池（StringTable）里的引用 注意，是一组必须活跃的引用，不是对象。\n现在知道了GC Root，但是我们都知道有分代的概念，新生代的gc和老年的代的gc回收的区域是不一样，那么这里的GC Root是不是应该不一样呢？肯定是不一样的。\n首先看一下新生代的GC\n新生代的区域一般都比较小，而且对象的存活率都比较低，所以按照前面说的GC Root在新生代的区域扫描就行了。但是会有一个问题？老年代存在引用新生代对象的可能啊？如果只扫描新生代的区域，会漏掉被老年代引用的对象，这些对象就会被清除掉，这是不允许的。\n如果这样的话，那是不是扫描一下老年代的对象，看是否引用新生代的对象是不是就ok了？嗯这么做肯定是ok的，但是老年代一般很大，而且存活的对象很多，会导致扫描占用很长的时间。那这个问题如何解？JVM是如何避免Minor GC时扫描全堆的？\n经过统计信息显示，老年代持有新生代对象引用的情况不足1%，根据这一特性JVM引入了卡表（card table）来实现这一目的。如下图所示：\n卡表的具体策略是将老年代的空间分成大小为512B的若干张卡（card）。卡表本身是单字节数组，数组中的每个元素对应着一张卡，当发生老年代引用新生代时，虚拟机将该卡对应的卡表元素设置为适当的值。如上图所示，卡表3被标记为脏（卡表还有另外的作用，标识并发标记阶段哪些块被修改过），之后Minor GC时通过扫描卡表就可以很快的识别哪些卡中存在老年代指向新生代的引用。这样虚拟机通过空间换时间的方式，避免了全堆扫描。\n所以新年代GC的GC Root包含2部分\n新生代中满足GC Root定义的对象 卡表中老年代引用新生代的对象 老年代的GC\n前面我们说了新生代的gc，我们以同样的思路来看看老年代的gc，老年代的GC Root如何来标记呢？只扫描老年代可以吗？当然是不行的，因为新生代中也可能存在老年代对象的引用，好在新生代并不大，所以老年代GC的时候还需要扫描一遍新生代。\n所以老年代GC的GC Root包含2部分\n老生代中满足GC Root定义的对象，如图节点1； 标记年轻代中活着的对象引用到的老年代的对象（指的是年轻代中还存活的引用类型对象，引用指向老年代中的对象）如图节点2、3； 并发标记的好坏? 标记作为垃圾回收的第一步，现在知道如何进行标记，接下来就是遍历这些对象，将所有未标记的对象清理就完成GC了。\n然而事实上并没有这么简单，如果标记的时候是STW的，那就是这么简单，但是如果标记过程都STW会造成暂停时间过长，给人的感觉就是系统一卡一卡的。\n于是就把标记的过程改成并发的进行，也就是CMS中并发标记的过程，然而这就是一切复杂问题的源头。虽然并发标记提升了标记的效率，但是因此却引发了一系列的问题。\n因为并发标记时，gc线程和用户线程是并行的，所以在这个过程中会出现下面的情况(需要了解三色标记法与读写屏障)：\n新生代晋升到老年代 黑色对象取消对灰色对象的引用(浮动垃圾) 黑色对象新增对白色对象的引用(漏标) 其实在三色标记法与读写屏障文中已经给出了解决方法\u0026ndash;添加读写屏障\n写屏障 + SATB 写屏障 + 增量更新 读屏障（Load Barrier） 在CMS并发标记阶段，使用 写屏障 + 增量更新 的方法，将上面出现的情况标记为dirty，这样最后再遍历处理一下Dirty集合中的对象就ok了\n重新标记阶段为什么还要扫描新生代？ 因为存在跨代引用，但是前面说过这种情况，通过读写屏障的方式标记这些为dirty，只需要扫描老年代和dirty集合就行了啊？哎，看来我还是太年轻，如果只扫描老年代和dirty集合会漏掉一部分，会是哪部分呢？老年代和dirty集合还没有覆盖完吗？\n是的，老年代和dirty集合的确没有覆盖完。我们来分析一下。老年代中经过初始标记和并发标记后，只有黑色对象和白色对象了，黑色的就是要留下的，白色的就是要被清除的。黑色对象是怎么来的？根据GC Root找到的，所以只要并发标记过程中，GC Root不发生变化，黑色对象就没有问题(不会漏标)，如果在并发标记过程中GC Root发生了变化呢？\n当并发标记过程中GC Root增加了，并且这个GC Root还引用了老年代中的对象，此时如果只扫描老年代和dirty集合就会漏标。因此重新标记阶段仍然需要扫描新生代。\n预处理阶段都干了啥？ 预处理阶段其实有2部分：\n预清理阶段 可终止的预处理 这个阶段的目的都是为了减轻后面的重新标记的压力，提前做一点重新标记阶段的工作。一般CMS的GC耗时80%都在remark阶段，所以预处理阶段也是为了减少remark阶段的STW时间。\n重新标记阶段需要做以下工作：\n遍历新生代对象，重新标记 根据GC Roots，重新标记 遍历老年代的Dirty Card，重新标记（这里的Dirty Card大部分已经在clean阶段处理过） 遍历新生代对象时，可能很多对象已经是不可达了，但是还是需要扫描。遍历Dirty Card做处理。\n这2部分其实就是预处理阶段帮助重新标记减轻压力的地方\n预清理阶段和可终止的预处理都会扫描Dirty Card做处理 可终止的预处理，尽量进行一次ygc，让不可达的对象被回收掉，remark阶段遍历新生代的对象成本小一点 具体这个阶段的详情见参考文档图解CMS垃圾回收机制，你值得拥有\n参考文档\n三色标记法与读写屏障 图解CMS垃圾回收机制，你值得拥有 java的gc为什么要分代？ ","permalink":"https://carlos19960601.github.io/posts/%E5%86%8D%E5%9B%9E%E9%A6%96cms%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/","summary":"前言 之前学习JVM垃圾回收时，主要是过了一遍垃圾收集算法，比如复制算法，标记-清除算法，标记-整理算法，在此基础上可以增加分代，每代采取不同的回收算法，以提高整体的分配和回收效率。然后过了一遍JVM中的垃圾收集器，比如Serial、Parallel Scavenge、Parallel New、CMS、G1等。\n自认为垃圾收集就是根据GC Root标记所有可达的对象，然后把所有没有标记的对象清除就ok了。是不是很简单。事实上垃圾收集也就是这么一回事，但是很多时候说起来简单，做起来却会出现很多问题。这篇文章就是记录我对CMS垃圾收集器的一些疑问并学习的过程。\n首先看一下CMS的整体流程(具体每个流程的详情就自行了解吧)\n如何进行标记？ 最近在看Golang的GC算法实现，里面用到了三色标记法，但是在我的知识库中对三色标记法有这个概念，是的，我只知道这个概念，不知道三色标记法是怎么一个流程，也不知道三色标记法在GC中怎么与运行的。于是就开始了我的探险之旅。\n在搜索了一下三色标记法（具体可以看一下文末参考文档中三色标记法与读写屏障了解详情）后，发现现代追踪式（可达性分析）的垃圾回收器几乎都借鉴了三色标记的算法思想，CMS垃圾收集器也不例外。\nGC Root有哪些？ 我们知道怎么进行标记了，但最初标记的时候需要一些根据才行啊，这些根据就是我们收的GC Root。GC Root有哪些？网上有很多的答案，我的理解就是\n当前活跃调用栈中的指向对象的引用 一些不会发生改变的数据所指向的引用 这里我使用的是引用，而不是对象，因为R大是这样说的（具体的问题见参考文档java的gc为什么要分代？）\n所谓“GC roots”，或者说tracing GC的“根集合”，就是一组必须活跃的引用。 例如说，这些引用可能包括：\n所有Java线程当前活跃的栈帧里指向GC堆里的对象的引用；换句话说，当前所有正在被调用的方法的引用类型的参数/局部变量/临时值。 VM的一些静态数据结构里指向GC堆里的对象的引用，例如说HotSpot VM里的Universe里有很多这样的引用。 JNI handles，包括global handles和local handles （看情况）所有当前被加载的Java类 （看情况）Java类的引用类型静态变量 （看情况）Java类的运行时常量池里的引用类型常量（String或Class类型） （看情况）String常量池（StringTable）里的引用 注意，是一组必须活跃的引用，不是对象。\n现在知道了GC Root，但是我们都知道有分代的概念，新生代的gc和老年的代的gc回收的区域是不一样，那么这里的GC Root是不是应该不一样呢？肯定是不一样的。\n首先看一下新生代的GC\n新生代的区域一般都比较小，而且对象的存活率都比较低，所以按照前面说的GC Root在新生代的区域扫描就行了。但是会有一个问题？老年代存在引用新生代对象的可能啊？如果只扫描新生代的区域，会漏掉被老年代引用的对象，这些对象就会被清除掉，这是不允许的。\n如果这样的话，那是不是扫描一下老年代的对象，看是否引用新生代的对象是不是就ok了？嗯这么做肯定是ok的，但是老年代一般很大，而且存活的对象很多，会导致扫描占用很长的时间。那这个问题如何解？JVM是如何避免Minor GC时扫描全堆的？\n经过统计信息显示，老年代持有新生代对象引用的情况不足1%，根据这一特性JVM引入了卡表（card table）来实现这一目的。如下图所示：\n卡表的具体策略是将老年代的空间分成大小为512B的若干张卡（card）。卡表本身是单字节数组，数组中的每个元素对应着一张卡，当发生老年代引用新生代时，虚拟机将该卡对应的卡表元素设置为适当的值。如上图所示，卡表3被标记为脏（卡表还有另外的作用，标识并发标记阶段哪些块被修改过），之后Minor GC时通过扫描卡表就可以很快的识别哪些卡中存在老年代指向新生代的引用。这样虚拟机通过空间换时间的方式，避免了全堆扫描。\n所以新年代GC的GC Root包含2部分\n新生代中满足GC Root定义的对象 卡表中老年代引用新生代的对象 老年代的GC\n前面我们说了新生代的gc，我们以同样的思路来看看老年代的gc，老年代的GC Root如何来标记呢？只扫描老年代可以吗？当然是不行的，因为新生代中也可能存在老年代对象的引用，好在新生代并不大，所以老年代GC的时候还需要扫描一遍新生代。\n所以老年代GC的GC Root包含2部分\n老生代中满足GC Root定义的对象，如图节点1； 标记年轻代中活着的对象引用到的老年代的对象（指的是年轻代中还存活的引用类型对象，引用指向老年代中的对象）如图节点2、3； 并发标记的好坏? 标记作为垃圾回收的第一步，现在知道如何进行标记，接下来就是遍历这些对象，将所有未标记的对象清理就完成GC了。\n然而事实上并没有这么简单，如果标记的时候是STW的，那就是这么简单，但是如果标记过程都STW会造成暂停时间过长，给人的感觉就是系统一卡一卡的。\n于是就把标记的过程改成并发的进行，也就是CMS中并发标记的过程，然而这就是一切复杂问题的源头。虽然并发标记提升了标记的效率，但是因此却引发了一系列的问题。\n因为并发标记时，gc线程和用户线程是并行的，所以在这个过程中会出现下面的情况(需要了解三色标记法与读写屏障)：\n新生代晋升到老年代 黑色对象取消对灰色对象的引用(浮动垃圾) 黑色对象新增对白色对象的引用(漏标) 其实在三色标记法与读写屏障文中已经给出了解决方法\u0026ndash;添加读写屏障\n写屏障 + SATB 写屏障 + 增量更新 读屏障（Load Barrier） 在CMS并发标记阶段，使用 写屏障 + 增量更新 的方法，将上面出现的情况标记为dirty，这样最后再遍历处理一下Dirty集合中的对象就ok了","title":"再回首CMS垃圾回收"}]